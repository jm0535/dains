{
  "hash": "d02784e49352a9b69021c884dcec5d8f",
  "result": {
    "engine": "knitr",
    "markdown": "---\nprefer-html: true\n---\n\n# Introduction to Data Analysis\n\n## Overview\n\nData analysis is a critical skill in modern natural sciences research. This chapter introduces the fundamental concepts, tools, and approaches that form the foundation of effective data analysis across various scientific disciplines. By the end of this chapter, you will understand:\n\n- Why data analysis matters in natural sciences\n- How to set up R and RStudio\n- The tidyverse philosophy and its advantages\n- Basic R programming concepts\n- How to work with data using modern R practices\n\n## Why Data Analysis Matters in Natural Sciences\n\nData analysis plays a pivotal role in natural sciences research for several important reasons:\n\n### Evidence-Based Decision Making\n\nData analysis transforms raw observations into actionable insights, enabling researchers and practitioners to make informed decisions about:\n\n- **Conservation strategies**: Identifying priority areas and species for protection\n- **Resource management**: Optimizing sustainable use of natural resources\n- **Agricultural planning**: Improving crop yields and farming practices\n- **Environmental interventions**: Designing effective pollution control measures\n- **Climate adaptation**: Planning for changing environmental conditions\n\n### Pattern Recognition\n\nThrough statistical analysis, researchers can identify patterns, trends, and relationships within natural systems that might not be apparent from casual observation alone. This applies to diverse fields including:\n\n- Ecology and population dynamics\n- Geology and earth processes\n- Marine biology and oceanography\n- Atmospheric science and climatology\n- Agriculture and food systems\n\n### Hypothesis Testing\n\nData analysis provides rigorous methods to test hypotheses about natural phenomena, allowing researchers to build and refine scientific theories about how natural systems function. This is fundamental across all scientific disciplines.\n\n### Prediction and Modeling\n\nAdvanced analytical techniques enable the development of predictive models that can forecast changes in natural systems, such as:\n\n- Species distribution shifts under climate change\n- Crop yield predictions based on weather patterns\n- Disease outbreak forecasting\n- Resource depletion projections\n- Ecosystem responses to disturbance\n\n::: {.callout-tip}\n## PROFESSIONAL TIP: Principles of Robust Experimental Design\n\nBefore diving into data analysis, ensure your experimental design follows these key principles:\n\n- **Formulate clear hypotheses**: Define specific, testable hypotheses before collecting data\n- **Control for confounding variables**: Identify and account for factors that might influence your results\n- **Randomize appropriately**: Randomly assign treatments to experimental units to reduce bias\n- **Include adequate replication**: Ensure sufficient sample sizes for statistical power\n- **Consider spatial and temporal scales**: Match your sampling design to the processes being studied\n- **Plan for appropriate controls**: Include positive, negative, and procedural controls as needed\n- **Pre-register your study**: Document your hypotheses and analysis plan before collecting data\n- **Plan for data analysis**: Select statistical methods based on your design, not just your results\n:::\n\n## Introduction to R and RStudio\n\n### Why R?\n\nR is a powerful programming language and environment specifically designed for statistical computing and graphics. It has become the standard tool for data analysis in many scientific disciplines.\n\n**Key advantages of R include:**\n\n| Advantage | Description |\n|-----------|-------------|\n| **Open-source and free** | Available to anyone without cost |\n| **Extensive package ecosystem** | Over 20,000 packages for specialized analyses |\n| **Reproducibility** | Code-based approach ensures analyses can be repeated |\n| **Flexibility** | Adaptable to virtually any analytical need |\n| **Active community** | Large user base provides support and development |\n| **Publication-quality graphics** | Create professional visualizations |\n| **Cross-platform** | Works on Windows, macOS, and Linux |\n\n### Installing R and RStudio\n\nTo get started with R, you need to install two pieces of software:\n\n1. **R** - The programming language itself\n2. **RStudio** - An integrated development environment (IDE) that makes working with R easier\n\n**Installation Steps:**\n\n1. Download and install R from [CRAN](https://cran.r-project.org/)\n   - Choose your operating system (Windows, macOS, or Linux)\n   - Follow the installation instructions\n\n2. Download and install RStudio from [Posit](https://posit.co/download/rstudio-desktop/)\n   - Choose the free Desktop version\n   - Follow the installation instructions\n\n::: {.callout-note}\n## Note: Install R First\n\nYou must install R before installing RStudio. RStudio is just an interface to R—it won't work without R installed on your computer.\n:::\n\n### The RStudio Interface\n\nWhen you open RStudio, you'll see four main panels:\n\n1. **Source Editor** (top-left): Where you write and edit R scripts\n2. **Console** (bottom-left): Where R commands are executed\n3. **Environment/History** (top-right): Shows your data objects and command history\n4. **Files/Plots/Packages/Help** (bottom-right): File browser, plot viewer, package manager, and help documentation\n\n## The Tidyverse: A Modern Approach to Data Science\n\n### What is the Tidyverse?\n\nThe **tidyverse** is a collection of R packages designed for data science that share a common philosophy, grammar, and data structures. It represents a modern, coherent approach to data analysis that emphasizes:\n\n- **Readability**: Code that is easy to read and understand\n- **Consistency**: Functions that work in predictable ways\n- **Composability**: Tools that work well together\n- **Human-centered design**: Focused on the analyst's workflow\n\n### Core Tidyverse Packages\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load the tidyverse (this loads multiple packages at once)\nlibrary(tidyverse)\n```\n:::\n\n\nThe tidyverse includes these core packages:\n\n| Package | Purpose |\n|---------|---------|\n| **ggplot2** | Data visualization |\n| **dplyr** | Data manipulation |\n| **tidyr** | Data tidying |\n| **readr** | Data import |\n| **purrr** | Functional programming |\n| **tibble** | Modern data frames |\n| **stringr** | String manipulation |\n| **forcats** | Factor handling |\n\n### The Pipe Operator\n\nOne of the most powerful features of the tidyverse is the pipe operator `%>%` (or the native R pipe `|>`). The pipe allows you to chain operations together in a readable, left-to-right flow:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Without pipes (nested functions - hard to read)\nround(mean(sqrt(c(1, 4, 9, 16, 25))), 2)\n\n# With pipes (left-to-right flow - easy to read)\nc(1, 4, 9, 16, 25) %>%\n  sqrt() %>%\n  mean() %>%\n  round(2)\n```\n:::\n\n\n::: {.callout-tip}\n## PROFESSIONAL TIP: Pipe Operator Shortcuts\n\n- **Keyboard shortcut**: Use `Ctrl+Shift+M` (Windows/Linux) or `Cmd+Shift+M` (macOS) to insert `%>%`\n- **Native pipe**: In R 4.1+, you can use the native pipe `|>` instead of `%>%`\n- **Best practice**: Put each function on its own line for readability\n:::\n\n### Tidy Data Principles\n\nThe tidyverse is built around the concept of **tidy data**:\n\n1. Each **variable** forms a column\n2. Each **observation** forms a row\n3. Each type of **observational unit** forms a table\n\nTidy data makes analysis easier because it provides a consistent structure that all tidyverse tools expect.\n\n## Installing Required Packages\n\nFor the analyses in this book, you'll need several R packages. Install them with the following code:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Core tidyverse packages\ninstall.packages(\"tidyverse\")\n\n# Statistical analysis\ninstall.packages(c(\"rstatix\", \"car\", \"performance\"))\n\n# Visualization enhancements\ninstall.packages(c(\"viridis\", \"patchwork\", \"scales\"))\n\n# Table formatting\ninstall.packages(c(\"knitr\", \"kableExtra\", \"gt\"))\n\n# For this book's datasets\ninstall.packages(\"readr\")\n```\n:::\n\n\n::: {.callout-important}\n## Important: Run This Once\n\nYou only need to install packages once on your computer. After installation, you just need to load them with `library()` at the start of each R session.\n:::\n\n## Your First R Analysis\n\nLet's walk through a complete analysis using real data to see R and the tidyverse in action.\n\n### Loading Data\n\nWe'll use the Palmer Penguins dataset, which contains measurements of penguins from Antarctica:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load the tidyverse\nlibrary(tidyverse)\n\n# Load the penguin dataset\npenguins <- read_csv(\"../data/environmental/climate_data.csv\")\n\n# View the first few rows\nhead(penguins)\n#> # A tibble: 6 × 8\n#>   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#>   <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl>\n#> 1 Adelie  Torgersen           39.1          18.7               181        3750\n#> 2 Adelie  Torgersen           39.5          17.4               186        3800\n#> 3 Adelie  Torgersen           40.3          18                 195        3250\n#> 4 Adelie  Torgersen           NA            NA                  NA          NA\n#> 5 Adelie  Torgersen           36.7          19.3               193        3450\n#> 6 Adelie  Torgersen           39.3          20.6               190        3650\n#> # ℹ 2 more variables: sex <chr>, year <dbl>\n```\n:::\n\n\n::: {.callout-note}\n## Code Explanation\n\n- `library(tidyverse)`: Loads all core tidyverse packages\n- `read_csv()`: A tidyverse function for reading CSV files (faster and smarter than base R's `read.csv()`)\n- `head()`: Shows the first 6 rows of the dataset\n:::\n\n### Exploring the Data Structure\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Get an overview of the data structure\nglimpse(penguins)\n#> Rows: 344\n#> Columns: 8\n#> $ species           <chr> \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"A…\n#> $ island            <chr> \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen\", …\n#> $ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n#> $ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n#> $ flipper_length_mm <dbl> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n#> $ body_mass_g       <dbl> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n#> $ sex               <chr> \"male\", \"female\", \"female\", NA, \"female\", \"male\", \"f…\n#> $ year              <dbl> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n# Summary statistics\nsummary(penguins)\n#>    species             island          bill_length_mm  bill_depth_mm  \n#>  Length:344         Length:344         Min.   :32.10   Min.   :13.10  \n#>  Class :character   Class :character   1st Qu.:39.23   1st Qu.:15.60  \n#>  Mode  :character   Mode  :character   Median :44.45   Median :17.30  \n#>                                        Mean   :43.92   Mean   :17.15  \n#>                                        3rd Qu.:48.50   3rd Qu.:18.70  \n#>                                        Max.   :59.60   Max.   :21.50  \n#>                                        NA's   :2       NA's   :2      \n#>  flipper_length_mm  body_mass_g       sex                 year     \n#>  Min.   :172.0     Min.   :2700   Length:344         Min.   :2007  \n#>  1st Qu.:190.0     1st Qu.:3550   Class :character   1st Qu.:2007  \n#>  Median :197.0     Median :4050   Mode  :character   Median :2008  \n#>  Mean   :200.9     Mean   :4202                      Mean   :2008  \n#>  3rd Qu.:213.0     3rd Qu.:4750                      3rd Qu.:2009  \n#>  Max.   :231.0     Max.   :6300                      Max.   :2009  \n#>  NA's   :2         NA's   :2\n```\n:::\n\n\n::: {.callout-note}\n## Code Explanation\n\n- `glimpse()`: A tidyverse function that provides a transposed view of the data, showing each column's name, type, and first values\n- `summary()`: Provides basic summary statistics for each column\n:::\n\n### Data Manipulation with dplyr\n\nThe `dplyr` package provides intuitive verbs for data manipulation:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Filter: Keep rows that match a condition\nadelie_penguins <- penguins %>%\n  filter(species == \"Adelie\")\n\n# Select: Keep only certain columns\nmeasurements <- penguins %>%\n  select(species, bill_length_mm, bill_depth_mm, body_mass_g)\n\n# Mutate: Create new columns\npenguins_with_ratio <- penguins %>%\n  mutate(bill_ratio = bill_length_mm / bill_depth_mm)\n\n# Arrange: Sort rows\nsorted_penguins <- penguins %>%\n  arrange(desc(body_mass_g))\n\n# Summarize: Calculate summary statistics\nspecies_summary <- penguins %>%\n  filter(!is.na(body_mass_g)) %>%\n  group_by(species) %>%\n  summarize(\n    n = n(),\n    mean_mass = mean(body_mass_g),\n    sd_mass = sd(body_mass_g),\n    min_mass = min(body_mass_g),\n    max_mass = max(body_mass_g)\n  )\n\n# Display the summary\nspecies_summary\n#> # A tibble: 3 × 6\n#>   species       n mean_mass sd_mass min_mass max_mass\n#>   <chr>     <int>     <dbl>   <dbl>    <dbl>    <dbl>\n#> 1 Adelie      151     3701.    459.     2850     4775\n#> 2 Chinstrap    68     3733.    384.     2700     4800\n#> 3 Gentoo      123     5076.    504.     3950     6300\n```\n:::\n\n\n::: {.callout-important}\n## Results Interpretation\n\nThe summary table shows key statistics for each penguin species:\n\n- **n**: Sample size (number of observations)\n- **mean_mass**: Average body mass in grams\n- **sd_mass**: Standard deviation, measuring variability\n- **min_mass/max_mass**: Range of body masses\n\nThis summary reveals that Gentoo penguins are the largest on average, while Chinstrap and Adelie penguins are more similar in size.\n:::\n\n### Visualization with ggplot2\n\nThe `ggplot2` package creates beautiful, publication-quality graphics:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Create a boxplot of body mass by species\nggplot(penguins, aes(x = species, y = body_mass_g, fill = species)) +\n  geom_boxplot(alpha = 0.7) +\n  geom_jitter(width = 0.2, alpha = 0.3, size = 1) +\n  scale_fill_viridis_d() +\n  labs(\n    title = \"Body Mass Distribution by Penguin Species\",\n    subtitle = \"Data from Palmer Station, Antarctica (2007-2009)\",\n    x = \"Species\",\n    y = \"Body Mass (g)\",\n    fill = \"Species\",\n    caption = \"Source: Palmer Penguins dataset\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    legend.position = \"none\"\n  )\n```\n\n::: {.cell-output-display}\n![Body mass distribution across three penguin species from Palmer Station, Antarctica.](01-introduction_files/figure-html/ggplot-basics-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n::: {.callout-note}\n## Code Explanation\n\nThe ggplot2 syntax follows a layered grammar of graphics:\n\n1. **`ggplot()`**: Initialize the plot with data and aesthetic mappings\n2. **`aes()`**: Define how variables map to visual properties\n3. **`geom_boxplot()`**: Add a boxplot layer\n4. **`geom_jitter()`**: Add individual points with slight horizontal spread\n5. **`scale_fill_viridis_d()`**: Apply a colorblind-friendly color palette\n6. **`labs()`**: Add labels and titles\n7. **`theme_minimal()`**: Apply a clean, minimal theme\n8. **`theme()`**: Further customize appearance\n:::\n\n### A Scatter Plot with Regression\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Create a scatter plot with regression lines\nggplot(penguins, aes(x = bill_length_mm, y = body_mass_g, color = species)) +\n  geom_point(alpha = 0.7, size = 2) +\n  geom_smooth(method = \"lm\", se = TRUE, alpha = 0.2) +\n  scale_color_viridis_d() +\n  labs(\n    title = \"Relationship Between Bill Length and Body Mass\",\n    subtitle = \"Linear relationships shown for each species\",\n    x = \"Bill Length (mm)\",\n    y = \"Body Mass (g)\",\n    color = \"Species\",\n    caption = \"Source: Palmer Penguins dataset\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\"\n  )\n```\n\n::: {.cell-output-display}\n![Relationship between bill length and body mass in three penguin species, showing positive correlations within each species.](01-introduction_files/figure-html/scatter-regression-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n## The Data Analysis Workflow\n\nEffective data analysis typically follows a structured workflow:\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n### 1. Import\n\nBring your data into R from files, databases, or APIs:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# CSV files\ndata <- read_csv(\"path/to/file.csv\")\n\n# Excel files (requires readxl package)\ndata <- readxl::read_excel(\"path/to/file.xlsx\")\n\n# From URLs\ndata <- read_csv(\"https://example.com/data.csv\")\n```\n:::\n\n\n### 2. Tidy\n\nRestructure data into a consistent format:\n\n- Each variable in its own column\n- Each observation in its own row\n- Each value in its own cell\n\n### 3. Transform\n\nManipulate data to create the variables you need:\n\n- Filter observations\n- Create new variables\n- Calculate summaries\n- Join multiple datasets\n\n### 4. Visualize\n\nCreate graphics to understand patterns:\n\n- Explore distributions\n- Identify relationships\n- Detect outliers\n- Generate hypotheses\n\n### 5. Model\n\nApply statistical methods to test hypotheses:\n\n- Fit regression models\n- Perform hypothesis tests\n- Estimate parameters\n- Make predictions\n\n### 6. Communicate\n\nShare your findings effectively:\n\n- Create reports with R Markdown or Quarto\n- Build interactive dashboards\n- Write scientific papers\n- Present to stakeholders\n\n## Types of Data in Natural Sciences\n\nUnderstanding your data type is crucial for choosing appropriate analytical methods:\n\n### Categorical Data\n\nCategorical data represent qualitative characteristics:\n\n- **Nominal**: Categories with no inherent order (species names, habitat types)\n- **Ordinal**: Categories with a meaningful order (pollution levels: low, medium, high)\n\n### Numerical Data\n\nNumerical data involve measurements or counts:\n\n- **Continuous**: Can take any value within a range (temperature, pH, biomass)\n- **Discrete**: Can only take specific values, usually counts (number of individuals)\n\n### Spatial Data\n\nSpatial data describe geographical distributions:\n\n- Coordinates (latitude/longitude)\n- Elevation or depth\n- Land cover maps\n- Remote sensing data\n\n### Temporal Data\n\nTemporal data track changes over time:\n\n- Time series measurements\n- Seasonal patterns\n- Long-term monitoring data\n- Growth curves\n\n## Best Practices for Reproducible Research\n\n::: {.callout-tip}\n## PROFESSIONAL TIP: Reproducible Research Practices\n\nAdopt these practices from the start of your research career:\n\n1. **Use R projects**: Organize your work in self-contained RStudio projects\n2. **Use relative paths**: Never use absolute file paths like `C:/Users/Name/...`\n3. **Document your code**: Add comments explaining *why*, not just *what*\n4. **Version control**: Use Git to track changes to your scripts\n5. **Save your environment**: Record package versions with `sessionInfo()`\n6. **Write functions**: Avoid copying and pasting code; write reusable functions\n7. **Use R Markdown/Quarto**: Combine code, results, and narrative in one document\n8. **Set seeds for reproducibility**: Use `set.seed()` before any random operations\n:::\n\n### Session Information\n\nAlways record your R environment for reproducibility:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Display session information\nsessionInfo()\n#> R version 4.4.3 (2025-02-28)\n#> Platform: x86_64-redhat-linux-gnu\n#> Running under: Fedora Linux 40 (Workstation Edition)\n#> \n#> Matrix products: default\n#> BLAS/LAPACK: FlexiBLAS OPENBLAS-OPENMP;  LAPACK version 3.12.0\n#> \n#> locale:\n#>  [1] LC_CTYPE=en_AU.UTF-8       LC_NUMERIC=C              \n#>  [3] LC_TIME=en_AU.UTF-8        LC_COLLATE=en_AU.UTF-8    \n#>  [5] LC_MONETARY=en_AU.UTF-8    LC_MESSAGES=en_AU.UTF-8   \n#>  [7] LC_PAPER=en_AU.UTF-8       LC_NAME=C                 \n#>  [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n#> [11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C       \n#> \n#> time zone: Australia/Brisbane\n#> tzcode source: system (glibc)\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices datasets  utils     methods   base     \n#> \n#> other attached packages:\n#>  [1] lubridate_1.9.4 forcats_1.0.0   stringr_1.5.1   dplyr_1.1.4    \n#>  [5] purrr_1.0.4     readr_2.1.5     tidyr_1.3.1     tibble_3.2.1   \n#>  [9] ggplot2_4.0.0   tidyverse_2.0.0\n#> \n#> loaded via a namespace (and not attached):\n#>  [1] utf8_1.2.5         generics_0.1.4     lattice_0.22-7     stringi_1.8.7     \n#>  [5] hms_1.1.3          digest_0.6.37      magrittr_2.0.3     evaluate_1.0.3    \n#>  [9] grid_4.4.3         timechange_0.3.0   RColorBrewer_1.1-3 fastmap_1.2.0     \n#> [13] Matrix_1.7-3       jsonlite_2.0.0     mgcv_1.9-3         viridisLite_0.4.2 \n#> [17] scales_1.4.0       CoprManager_0.5.7  codetools_0.2-20   cli_3.6.5         \n#> [21] rlang_1.1.6        crayon_1.5.3       splines_4.4.3      bit64_4.6.0-1     \n#> [25] withr_3.0.2        yaml_2.3.10        tools_4.4.3        parallel_4.4.3    \n#> [29] tzdb_0.5.0         vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#> [33] htmlwidgets_1.6.4  bit_4.6.0          vroom_1.6.5        pkgconfig_2.0.3   \n#> [37] pillar_1.10.2      gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#> [41] tidyselect_1.2.1   knitr_1.50         dichromat_2.0-0.1  farver_2.1.2      \n#> [45] nlme_3.1-168       htmltools_0.5.8.1  rmarkdown_2.29     labeling_0.4.3    \n#> [49] compiler_4.4.3     S7_0.2.0\n```\n:::\n\n\n## Summary\n\nIn this chapter, we introduced:\n\n- The importance of data analysis in natural sciences research\n- R and RStudio as powerful tools for data analysis\n- The tidyverse philosophy and its core packages\n- Basic data manipulation with `dplyr`\n- Data visualization with `ggplot2`\n- The data analysis workflow\n- Types of data in natural sciences\n- Best practices for reproducible research\n\nIn the next chapter, we'll dive deeper into data basics, learning more about data structures, importing various file formats, and preparing data for analysis.\n\n## Exercises\n\n1. **Install and explore**: Install R and RStudio on your computer. Open RStudio and explore the interface.\n\n2. **Load the tidyverse**: Run `library(tidyverse)` and note which packages are loaded.\n\n3. **Explore built-in data**: Use `head()`, `glimpse()`, and `summary()` on R's built-in `iris` dataset.\n\n4. **Practice pipes**: Rewrite this nested code using pipes:\n   ```r\n   round(mean(sqrt(c(4, 9, 16, 25, 36))), 2)\n   ```\n\n5. **Create a summary**: Using the penguins data (or `iris`), calculate the mean and standard deviation of a numerical variable for each group of a categorical variable.\n\n6. **Make a plot**: Create a scatter plot of two numerical variables from the `iris` dataset, colored by species.\n\n7. **Research question**: Think about a research question in your field. What type of data would you need? What visualizations might help you explore the data?\n\n## References\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}