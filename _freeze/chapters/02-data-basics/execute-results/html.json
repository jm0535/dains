{
  "hash": "fc8c9a0562f74505617bdad50f314c31",
  "result": {
    "engine": "knitr",
    "markdown": "---\nprefer-html: true\n---\n\n# Data Basics\n\n## Introduction\n\n::: {.callout-note}\n## Learning Objectives\n\nBy the end of this chapter, you will be able to:\n\n1.  Distinguish between different data types and structures in R\n2.  Import data from CSV and other file formats\n3.  Clean datasets by handling missing values and inconsistencies\n4.  Transform data using `dplyr` verbs (filter, select, mutate, summarize)\n5.  Perform initial exploratory data analysis to understand dataset properties\n:::\n\nThis chapter covers the fundamental concepts of working with data in R. You'll learn how to import, clean, and prepare data for analysis, which are essential skills for any data analysis project across all natural science disciplines.\n\n## Understanding Data Structures\n\nBefore diving into data analysis, it's important to understand the basic data structures in R:\n\n### Data Types\n\nR has several basic data types:\n\n- **Numeric**: Decimal values (e.g., measurements of temperature, pH, concentration, or distance)\n- **Integer**: Whole numbers (e.g., counts of organisms, samples, or observations)\n- **Character**: Text strings (e.g., species names, site descriptions, or treatment labels)\n- **Logical**: TRUE/FALSE values (e.g., presence/absence data or condition met/not met)\n- **Factor**: Categorical variables with levels (e.g., experimental treatments, taxonomic classifications, or soil types)\n- **Date/Time**: Temporal data (e.g., sampling dates, observation times, or seasonal markers)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Examples of different data types\nnumeric_example <- 25.4  # Temperature in Celsius\ncharacter_example <- \"Adelie\"  # Penguin species\nlogical_example <- TRUE  # Presence/absence data\nfactor_example <- factor(c(\"Control\", \"Treatment\", \"Control\"),\n                         levels = c(\"Control\", \"Treatment\"))\ndate_example <- as.Date(\"2020-07-15\")  # Sampling date\n\n# Print examples\nprint(numeric_example)\n#> [1] 25.4\nprint(character_example)\n#> [1] \"Adelie\"\nprint(logical_example)\n#> [1] TRUE\nprint(factor_example)\n#> [1] Control   Treatment Control  \n#> Levels: Control Treatment\nprint(date_example)\n#> [1] \"2020-07-15\"\n```\n:::\n\n\n::: {.callout-note}\n## Code Explanation\n\nThis code demonstrates the fundamental data types in R:\n\n1. **Numeric Data**:\n   - Created a decimal value representing temperature in Celsius\n   - Common for environmental measurements and continuous data\n\n2. **Character Data**:\n   - Created a text string for a penguin species name\n   - Used for categorical variables like species names or site descriptions\n\n3. **Logical Data**:\n   - Created a TRUE value representing presence/absence\n   - Used for binary data or conditions in analyses\n\n4. **Factor Data**:\n   - Created an ordered categorical variable with two levels\n   - Explicitly defined factor levels (\"Control\" and \"Treatment\")\n   - Essential for statistical analyses and proper plotting order\n\n5. **Date Data**:\n   - Created a date object using the `as.Date()` function\n   - Used for temporal data in ecological studies\n:::\n\n::: {.callout-important}\n## Results Interpretation\n\nThe output shows how R stores and displays different data types:\n\n1. **Numeric Data**:\n   - Displayed as 25.4 without type indication\n   - R treats this as a continuous numeric value for calculations\n\n2. **Character Data**:\n   - Displayed as \"Adelie\" with quotation marks indicating text\n   - Cannot be used for numerical operations\n\n3. **Logical Data**:\n   - Displayed as TRUE (without quotation marks)\n   - Can be used in conditional operations and converts to 1 (TRUE) or 0 (FALSE) in calculations\n\n4. **Factor Data**:\n   - Displayed with levels information: Control, Treatment, Control\n   - Internally stored as integers with labels\n   - Order of levels is preserved as specified\n\n5. **Date Data**:\n   - Displayed in standardized YYYY-MM-DD format\n   - Allows for time-based calculations and comparisons\n:::\n\n::: {.callout-tip}\n## PROFESSIONAL TIP: Data Management Best Practices\n\nProper data management is critical for reproducible research in natural sciences:\n\n- **Document metadata**: Always maintain detailed records about data collection methods, units, and variable definitions\n- **Use consistent naming conventions**: Create clear, consistent file and variable names (e.g., `site_01_temp_2023.csv` instead of `data1.csv`)\n- **Preserve raw data**: Never modify your original data files; always work with copies for cleaning and analysis\n- **Version control**: Use Git or similar tools to track changes to your data processing scripts\n- **Implement quality control**: Create automated checks for impossible values, outliers, and inconsistencies\n- **Plan for missing data**: Develop a consistent strategy for handling missing values before analysis begins\n- **Create tidy data**: Structure data with one observation per row and one variable per column\n- **Use open formats**: Store data in non-proprietary formats (CSV, TSV) for long-term accessibility\n- **Back up regularly**: Maintain multiple copies of your data in different physical locations\n- **Consider data repositories**: Share your data through repositories like Dryad, Zenodo, or discipline-specific databases\n:::\n\n### Data Structures in R\n\nR has several data structures for organizing information:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load real datasets\nlibrary(readr)\npenguins <- read_csv(\"../data/environmental/climate_data.csv\")\ncrops <- read_csv(\"../data/agriculture/crop_yields.csv\")\n\n# Vector example - penguin bill lengths\nbill_lengths <- na.omit(penguins$bill_length_mm[1:10])\nprint(bill_lengths)\n#> [1] 39.1 39.5 40.3 36.7 39.3 38.9 39.2 34.1 42.0\n#> attr(,\"na.action\")\n#> [1] 4\n#> attr(,\"class\")\n#> [1] \"omit\"\n\n# Matrix example - create a matrix from penguin measurements\npenguin_matrix <- as.matrix(penguins[1:5, 3:6])\nprint(penguin_matrix)\n#>      bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#> [1,]           39.1          18.7               181        3750\n#> [2,]           39.5          17.4               186        3800\n#> [3,]           40.3          18.0               195        3250\n#> [4,]             NA            NA                NA          NA\n#> [5,]           36.7          19.3               193        3450\n\n# Data frame example - first few rows of penguin data\npenguin_data <- penguins[1:5, ]\nprint(penguin_data)\n#> # A tibble: 5 × 8\n#>   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#>   <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl>\n#> 1 Adelie  Torgersen           39.1          18.7               181        3750\n#> 2 Adelie  Torgersen           39.5          17.4               186        3800\n#> 3 Adelie  Torgersen           40.3          18                 195        3250\n#> 4 Adelie  Torgersen           NA            NA                  NA          NA\n#> 5 Adelie  Torgersen           36.7          19.3               193        3450\n#> # ℹ 2 more variables: sex <chr>, year <dbl>\n\n# List example - store different aspects of the dataset\npenguin_summary <- list(\n  species = unique(penguins$species),\n  avg_bill_length = mean(penguins$bill_length_mm, na.rm = TRUE),\n  sample_size = nrow(penguins),\n  years = unique(penguins$year)\n)\nprint(penguin_summary)\n#> $species\n#> [1] \"Adelie\"    \"Gentoo\"    \"Chinstrap\"\n#> \n#> $avg_bill_length\n#> [1] 43.92193\n#> \n#> $sample_size\n#> [1] 344\n#> \n#> $years\n#> [1] 2007 2008 2009\n```\n:::\n\n\n::: {.callout-note}\n## Code Explanation\n\nThis code demonstrates the main data structures in R using real ecological datasets:\n\n1. **Data Loading**:\n   - Uses `readr::read_csv()` to import real datasets on penguins and crop yields\n   - Loads data with proper data types and handling\n\n2. **Vector Creation**:\n   - Creates a numeric vector of bill lengths\n   - Uses `na.omit()` to remove missing values\n   - Subsets only the first 10 values with `[1:10]`\n\n3. **Matrix Construction**:\n   - Creates a numeric matrix from penguin measurements\n   - Uses `as.matrix()` to convert data frame columns to matrix\n   - Selects rows 1-5 and columns 3-6 using indexing\n\n4. **Data Frame Handling**:\n   - Demonstrates a data frame (the most common data structure)\n   - Shows how to subset rows while keeping all columns\n\n5. **List Creation**:\n   - Creates a list to store heterogeneous data elements\n   - Contains different data types: character vector, numeric value, and integer\n   - Demonstrates how lists can store complex, nested information\n:::\n\n::: {.callout-important}\n## Results Interpretation\n\nThe output reveals the structure and properties of different R data types:\n\n1. **Vector Output**:\n   - Shows a one-dimensional array of bill length measurements\n   - All elements are of the same type (numeric)\n   - Suitable for storing a single variable's values\n\n2. **Matrix Output**:\n   - Displays a two-dimensional array of measurements\n   - All values must be of the same type (converted to numeric)\n   - Row and column indices are shown\n   - Efficient for mathematical operations but less flexible than data frames\n\n3. **Data Frame Output**:\n   - Shows a tabular structure with different variable types\n   - Preserves column names and data types\n   - The foundation of most data analysis in R\n   - Each column can have a different data type\n\n4. **List Output**:\n   - Displays a collection of disparate elements\n   - Shows the flexibility of lists for storing mixed data\n   - Demonstrates named elements for easy access\n   - Ideal for storing complex results and heterogeneous data\n:::\n\n## Importing Data\n\n### Reading Data Files\n\nR provides several functions for importing data from different file formats:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# CSV files - Palmer Penguins dataset\npenguins_csv <- read.csv(\"../data/environmental/climate_data.csv\")\nhead(penguins_csv, 3)\n#>   species    island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#> 1  Adelie Torgersen           39.1          18.7               181        3750\n#> 2  Adelie Torgersen           39.5          17.4               186        3800\n#> 3  Adelie Torgersen           40.3          18.0               195        3250\n#>      sex year\n#> 1   male 2007\n#> 2 female 2007\n#> 3 female 2007\n\n# Using the tidyverse approach for better handling\nlibrary(tidyverse)\npenguins_tidy <- readr::read_csv(\"../data/environmental/climate_data.csv\")\nhead(penguins_tidy, 3)\n#> # A tibble: 3 × 8\n#>   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#>   <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl>\n#> 1 Adelie  Torgersen           39.1          18.7               181        3750\n#> 2 Adelie  Torgersen           39.5          17.4               186        3800\n#> 3 Adelie  Torgersen           40.3          18                 195        3250\n#> # ℹ 2 more variables: sex <chr>, year <dbl>\n\n# Crop yields dataset\ncrops_csv <- read.csv(\"../data/agriculture/crop_yields.csv\")\nhead(crops_csv, 3)\n#>        Entity Code Year Wheat..tonnes.per.hectare. Rice..tonnes.per.hectare.\n#> 1 Afghanistan  AFG 1961                     1.0220                     1.519\n#> 2 Afghanistan  AFG 1962                     0.9735                     1.519\n#> 3 Afghanistan  AFG 1963                     0.8317                     1.519\n#>   Maize..tonnes.per.hectare. Soybeans..tonnes.per.hectare.\n#> 1                      1.400                            NA\n#> 2                      1.400                            NA\n#> 3                      1.426                            NA\n#>   Potatoes..tonnes.per.hectare. Beans..tonnes.per.hectare.\n#> 1                        8.6667                         NA\n#> 2                        7.6667                         NA\n#> 3                        8.1333                         NA\n#>   Peas..tonnes.per.hectare. Cassava..tonnes.per.hectare.\n#> 1                        NA                           NA\n#> 2                        NA                           NA\n#> 3                        NA                           NA\n#>   Barley..tonnes.per.hectare. Cocoa.beans..tonnes.per.hectare.\n#> 1                        1.08                               NA\n#> 2                        1.08                               NA\n#> 3                        1.08                               NA\n#>   Bananas..tonnes.per.hectare.\n#> 1                           NA\n#> 2                           NA\n#> 3                           NA\n```\n:::\n\n\n::: {.callout-note}\n## Code Explanation\n\nThis code demonstrates different methods for importing data in R:\n\n1. **Base R Import**:\n   - Uses `read.csv()` from base R to import the penguin dataset\n   - Simple approach that works without additional packages\n   - Generally slower for large datasets and less flexible with column types\n\n2. **Tidyverse Import**:\n   - Uses `readr::read_csv()` from the tidyverse ecosystem\n   - More efficient for large datasets and better type inference\n   - Maintains consistent column types and handles problematic values better\n\n3. **Data Preview**:\n   - Uses `head()` with argument `3` to display just the first three rows\n   - Allows quick inspection of data structure without overwhelming output\n   - Essential first step to verify successful import and correct structure\n\n4. **Multiple Datasets**:\n   - Demonstrates importing different datasets (penguins and crop yields)\n   - Shows the same approach works across various data sources\n:::\n\n::: {.callout-important}\n## Results Interpretation\n\nThe output reveals differences between import methods and gives insight into the datasets:\n\n1. **Data Structure Visibility**:\n   - Both datasets show proper column names and values\n   - The tidyverse import (readr) provides cleaner output with column types\n   - Types are indicated (<dbl> for numeric, <chr> for character, etc.)\n\n2. **Import Method Comparison**:\n   - Base R (`read.csv()`) and tidyverse (`read_csv()`) produce similar results\n   - Tidyverse version provides more metadata about column types\n   - Both successfully imported the data with proper structure\n\n3. **Data Content Preview**:\n   - Penguin data contains morphological measurements and categorical variables\n   - Crop yield data includes countries, years, and production statistics\n   - Both datasets appear properly formatted for analysis\n:::\n\n### Exploring Real-World Datasets\n\nLet's explore some of the real-world datasets we have available:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Palmer Penguins dataset\npenguins <- read_csv(\"../data/environmental/climate_data.csv\")\nglimpse(penguins)\n#> Rows: 344\n#> Columns: 8\n#> $ species           <chr> \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"A…\n#> $ island            <chr> \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen\", …\n#> $ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n#> $ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n#> $ flipper_length_mm <dbl> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n#> $ body_mass_g       <dbl> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n#> $ sex               <chr> \"male\", \"female\", \"female\", NA, \"female\", \"male\", \"f…\n#> $ year              <dbl> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n# Basic summary statistics\nsummary(penguins$bill_length_mm)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n#>   32.10   39.23   44.45   43.92   48.50   59.60       2\nsummary(penguins$flipper_length_mm)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n#>   172.0   190.0   197.0   200.9   213.0   231.0       2\n\n# Crop yields dataset\ncrops <- read_csv(\"../data/agriculture/crop_yields.csv\")\nglimpse(crops)\n#> Rows: 13,075\n#> Columns: 14\n#> $ Entity                             <chr> \"Afghanistan\", \"Afghanistan\", \"Afgh…\n#> $ Code                               <chr> \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", …\n#> $ Year                               <dbl> 1961, 1962, 1963, 1964, 1965, 1966,…\n#> $ `Wheat (tonnes per hectare)`       <dbl> 1.0220, 0.9735, 0.8317, 0.9510, 0.9…\n#> $ `Rice (tonnes per hectare)`        <dbl> 1.5190, 1.5190, 1.5190, 1.7273, 1.7…\n#> $ `Maize (tonnes per hectare)`       <dbl> 1.4000, 1.4000, 1.4260, 1.4257, 1.4…\n#> $ `Soybeans (tonnes per hectare)`    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#> $ `Potatoes (tonnes per hectare)`    <dbl> 8.6667, 7.6667, 8.1333, 8.6000, 8.8…\n#> $ `Beans (tonnes per hectare)`       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#> $ `Peas (tonnes per hectare)`        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#> $ `Cassava (tonnes per hectare)`     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#> $ `Barley (tonnes per hectare)`      <dbl> 1.0800, 1.0800, 1.0800, 1.0857, 1.0…\n#> $ `Cocoa beans (tonnes per hectare)` <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#> $ `Bananas (tonnes per hectare)`     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n```\n:::\n\n\n## Data Cleaning and Preparation\n\n### Handling Missing Values\n\nMissing values are common in scientific datasets and need to be addressed before analysis:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Check for missing values in the penguins dataset\nsum(is.na(penguins))\n#> [1] 19\ncolSums(is.na(penguins))\n#>           species            island    bill_length_mm     bill_depth_mm \n#>                 0                 0                 2                 2 \n#> flipper_length_mm       body_mass_g               sex              year \n#>                 2                 2                11                 0\n\n# Create a complete cases dataset\npenguins_complete <- na.omit(penguins)\nprint(paste(\"Original dataset rows:\", nrow(penguins)))\n#> [1] \"Original dataset rows: 344\"\nprint(paste(\"Complete cases rows:\", nrow(penguins_complete)))\n#> [1] \"Complete cases rows: 333\"\n\n# Replace missing values with the mean for numeric columns\npenguins_imputed <- penguins\npenguins_imputed$bill_length_mm[is.na(penguins_imputed$bill_length_mm)] <-\n  mean(penguins_imputed$bill_length_mm, na.rm = TRUE)\npenguins_imputed$bill_depth_mm[is.na(penguins_imputed$bill_depth_mm)] <-\n  mean(penguins_imputed$bill_depth_mm, na.rm = TRUE)\n\n# Check if missing values were replaced\nsum(is.na(penguins_imputed$bill_length_mm))\n#> [1] 0\n```\n:::\n\n\n::: {.callout-note}\n## Code Explanation\n\nThis code demonstrates essential techniques for handling missing values in ecological data:\n\n1. **Missing Value Detection**:\n   - Uses `is.na()` to identify missing values in the dataset\n   - `sum(is.na())` counts the total number of missing values\n   - `colSums(is.na())` reports missing values per column\n   - Critical first step in data cleaning\n\n2. **Complete Case Analysis**:\n   - Uses `na.omit()` to remove rows with any missing values\n   - Creates a new dataset (`penguins_complete`) with only complete rows\n   - Compares the row count before and after removal\n   - Simple but can lead to significant data loss\n\n3. **Mean Imputation**:\n   - Creates a copy of the original dataset (`penguins_imputed`)\n   - Replaces missing values with column means\n   - Uses logical indexing with `is.na()` to target only missing values\n   - Calculates means with `na.rm = TRUE` to ignore missing values\n   - Verifies imputation success with another missing value check\n:::\n\n::: {.callout-important}\n## Results Interpretation\n\nThe output reveals the extent and impact of missing data:\n\n1. **Missing Data Quantity**:\n   - The total number of missing values in the dataset\n   - The distribution of missing values across columns\n   - Some columns (like bill measurements) have more missing values than others\n\n2. **Data Loss Impact**:\n   - The original dataset has more rows than the complete cases dataset\n   - The difference represents the number of incomplete observations\n   - In ecological studies, this data loss can introduce bias if missingness isn't random\n\n3. **Imputation Effectiveness**:\n   - After imputation, specific columns no longer contain missing values\n   - The final check (showing 0) confirms successful imputation\n   - This approach preserves sample size but may reduce variability\n:::\n\n::: {.callout-tip}\n## PROFESSIONAL TIP: Handling Missing Values in Ecological Data\n\nWhen dealing with missing values in ecological datasets:\n\n1. **Understand Missing Data Mechanisms**:\n   - **MCAR (Missing Completely At Random)**: Missingness unrelated to any variables (e.g., equipment failure)\n   - **MAR (Missing At Random)**: Missingness related to observed variables (e.g., more missing values in certain species)\n   - **MNAR (Missing Not At Random)**: Missingness related to the missing values themselves (e.g., very small values not detected)\n\n2. **Select Appropriate Handling Methods**:\n   - **Complete case analysis**: Appropriate for MCAR data with few missing values\n   - **Mean/median imputation**: Simple but can underestimate variance\n   - **Multiple imputation**: Creates several imputed datasets to account for uncertainty\n   - **Model-based imputation**: Uses relationships between variables to predict missing values\n   - **Maximum likelihood**: Estimates parameters directly from available data\n\n3. **Document and Report**:\n   - Always report the extent of missing data\n   - Document your handling approach and rationale\n   - Consider sensitivity analyses with different approaches\n   - Acknowledge potential biases introduced by missing data handling\n:::\n\n### Data Transformation\n\nOften, you'll need to transform variables to meet statistical assumptions or for better visualization:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load the biodiversity dataset\nbiodiversity <- read_csv(\"../data/ecology/biodiversity.csv\")\nglimpse(biodiversity)\n#> Rows: 500\n#> Columns: 24\n#> $ binomial_name     <chr> \"Abutilon pitcairnense\", \"Acaena exigua\", \"Acalypha …\n#> $ country           <chr> \"Pitcairn\", \"United States\", \"Congo\", \"Saint Helena,…\n#> $ continent         <chr> \"Oceania\", \"North America\", \"Africa\", \"Africa\", \"Oce…\n#> $ group             <chr> \"Flowering Plant\", \"Flowering Plant\", \"Flowering Pla…\n#> $ year_last_seen    <chr> \"2000-2020\", \"1980-1999\", \"1940-1959\", \"Before 1900\"…\n#> $ threat_AA         <dbl> 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1…\n#> $ threat_BRU        <dbl> 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0…\n#> $ threat_RCD        <dbl> 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0…\n#> $ threat_ISGD       <dbl> 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ threat_EPM        <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ threat_CC         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ threat_HID        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ threat_P          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ threat_TS         <dbl> 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ threat_NSM        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ threat_GE         <dbl> 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ threat_NA         <dbl> 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0…\n#> $ action_LWP        <dbl> 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0…\n#> $ action_SM         <dbl> 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ action_LP         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ action_RM         <dbl> 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ action_EA         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ action_NA         <dbl> 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n#> $ red_list_category <chr> \"Extinct in the Wild\", \"Extinct\", \"Extinct\", \"Extinc…\n\n# Log transformation of a skewed variable (if available)\nif(\"n\" %in% colnames(biodiversity)) {\n  biodiversity$log_n <- log(biodiversity$n + 1)  # Add 1 to handle zeros\n\n  # Compare original and transformed\n  summary(biodiversity$n)\n  summary(biodiversity$log_n)\n}\n\n# Standardization (z-score) of penguin measurements\npenguins_std <- penguins %>%\n  mutate(\n    bill_length_std = scale(bill_length_mm),\n    flipper_length_std = scale(flipper_length_mm),\n    body_mass_std = scale(body_mass_g)\n  )\n\n# View the first few rows of the transformed data\nhead(select(penguins_std, species, bill_length_mm, bill_length_std,\n             flipper_length_mm, flipper_length_std), 5)\n#> # A tibble: 5 × 5\n#>   species bill_length_mm bill_length_std[,1] flipper_length_mm\n#>   <chr>            <dbl>               <dbl>             <dbl>\n#> 1 Adelie            39.1              -0.883               181\n#> 2 Adelie            39.5              -0.810               186\n#> 3 Adelie            40.3              -0.663               195\n#> 4 Adelie            NA                NA                    NA\n#> 5 Adelie            36.7              -1.32                193\n#> # ℹ 1 more variable: flipper_length_std <dbl[,1]>\n```\n:::\n\n\n### Creating New Variables\n\nCreating new variables from existing ones is a common data preparation task:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Create new variables in the penguins dataset\npenguins_derived <- penguins %>%\n  filter(!is.na(bill_length_mm) & !is.na(bill_depth_mm)) %>%\n  mutate(\n    bill_ratio = bill_length_mm / bill_depth_mm,\n    size_category = case_when(\n      body_mass_g < 3500 ~ \"Small\",\n      body_mass_g < 4500 ~ \"Medium\",\n      TRUE ~ \"Large\"\n    )\n  )\n\n# View the new variables\nhead(select(penguins_derived, species, bill_length_mm, bill_depth_mm,\n             bill_ratio, body_mass_g, size_category), 5)\n#> # A tibble: 5 × 6\n#>   species bill_length_mm bill_depth_mm bill_ratio body_mass_g size_category\n#>   <chr>            <dbl>         <dbl>      <dbl>       <dbl> <chr>        \n#> 1 Adelie            39.1          18.7       2.09        3750 Medium       \n#> 2 Adelie            39.5          17.4       2.27        3800 Medium       \n#> 3 Adelie            40.3          18         2.24        3250 Small        \n#> 4 Adelie            36.7          19.3       1.90        3450 Small        \n#> 5 Adelie            39.3          20.6       1.91        3650 Medium\n```\n:::\n\n\n## Data Manipulation with dplyr\n\nThe dplyr package provides a powerful grammar for data manipulation:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(dplyr)\n\n# Filter rows - only Adelie penguins\nadelie_penguins <- penguins %>%\n  filter(species == \"Adelie\")\nhead(adelie_penguins, 3)\n#> # A tibble: 3 × 8\n#>   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#>   <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl>\n#> 1 Adelie  Torgersen           39.1          18.7               181        3750\n#> 2 Adelie  Torgersen           39.5          17.4               186        3800\n#> 3 Adelie  Torgersen           40.3          18                 195        3250\n#> # ℹ 2 more variables: sex <chr>, year <dbl>\n\n# Select columns - focus on measurements\npenguin_measurements <- penguins %>%\n  select(species, island, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g)\nhead(penguin_measurements, 3)\n#> # A tibble: 3 × 6\n#>   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#>   <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl>\n#> 1 Adelie  Torgersen           39.1          18.7               181        3750\n#> 2 Adelie  Torgersen           39.5          17.4               186        3800\n#> 3 Adelie  Torgersen           40.3          18                 195        3250\n\n# Create new variables\npenguins_analyzed <- penguins %>%\n  mutate(\n    bill_ratio = bill_length_mm / bill_depth_mm,\n    body_mass_kg = body_mass_g / 1000\n  )\nhead(select(penguins_analyzed, species, bill_ratio, body_mass_kg), 3)\n#> # A tibble: 3 × 3\n#>   species bill_ratio body_mass_kg\n#>   <chr>        <dbl>        <dbl>\n#> 1 Adelie        2.09         3.75\n#> 2 Adelie        2.27         3.8 \n#> 3 Adelie        2.24         3.25\n\n# Summarize data by species\npenguin_summary <- penguins %>%\n  group_by(species) %>%\n  summarize(\n    count = n(),\n    avg_bill_length = mean(bill_length_mm, na.rm = TRUE),\n    avg_bill_depth = mean(bill_depth_mm, na.rm = TRUE),\n    avg_body_mass = mean(body_mass_g, na.rm = TRUE)\n  ) %>%\n  arrange(desc(avg_body_mass))\nprint(penguin_summary)\n#> # A tibble: 3 × 5\n#>   species   count avg_bill_length avg_bill_depth avg_body_mass\n#>   <chr>     <int>           <dbl>          <dbl>         <dbl>\n#> 1 Gentoo      124            47.5           15.0         5076.\n#> 2 Chinstrap    68            48.8           18.4         3733.\n#> 3 Adelie      152            38.8           18.3         3701.\n\n# Analyze crop yields data\ncrop_summary <- crops %>%\n  filter(!is.na(`Wheat (tonnes per hectare)`)) %>%\n  group_by(Entity) %>%\n  summarize(\n    years_recorded = n(),\n    avg_wheat_yield = mean(`Wheat (tonnes per hectare)`, na.rm = TRUE),\n    max_wheat_yield = max(`Wheat (tonnes per hectare)`, na.rm = TRUE)\n  ) %>%\n  arrange(desc(avg_wheat_yield)) %>%\n  head(10)  # Top 10 countries by average wheat yield\n\nprint(crop_summary)\n#> # A tibble: 10 × 4\n#>    Entity          years_recorded avg_wheat_yield max_wheat_yield\n#>    <chr>                    <int>           <dbl>           <dbl>\n#>  1 Belgium                     19            8.54           10.0 \n#>  2 Netherlands                 58            7.03            9.29\n#>  3 Ireland                     58            6.83           10.7 \n#>  4 United Kingdom              58            6.37            8.98\n#>  5 Denmark                     58            6.18            8.24\n#>  6 Luxembourg                  19            5.98            6.82\n#>  7 Germany                     58            5.89            8.63\n#>  8 Europe, Western             58            5.72            7.88\n#>  9 France                      58            5.65            7.80\n#> 10 Northern Europe             58            5.59            7.21\n```\n:::\n\n\n## Exploratory Data Analysis\n\nBefore diving into formal statistical tests, it's essential to explore your data:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Basic summary statistics\nsummary(penguins$bill_length_mm)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n#>   32.10   39.23   44.45   43.92   48.50   59.60       2\nsummary(penguins$flipper_length_mm)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n#>   172.0   190.0   197.0   200.9   213.0   231.0       2\nsummary(penguins$body_mass_g)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n#>    2700    3550    4050    4202    4750    6300       2\n\n# Correlation between variables\ncor_matrix <- cor(\n  penguins %>%\n    select(bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g),\n  use = \"complete.obs\"\n)\nprint(cor_matrix)\n#>                   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#> bill_length_mm         1.0000000    -0.2350529         0.6561813   0.5951098\n#> bill_depth_mm         -0.2350529     1.0000000        -0.5838512  -0.4719156\n#> flipper_length_mm      0.6561813    -0.5838512         1.0000000   0.8712018\n#> body_mass_g            0.5951098    -0.4719156         0.8712018   1.0000000\n\n# Basic visualization - histogram of bill lengths\nlibrary(ggplot2)\nggplot(penguins, aes(x = bill_length_mm)) +\n  geom_histogram(binwidth = 1, fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Distribution of Penguin Bill Lengths\",\n       x = \"Bill Length (mm)\",\n       y = \"Frequency\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](02-data-basics_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=100%}\n:::\n\n```{.r .cell-code}\n\n# Boxplot of body mass by species\nggplot(penguins, aes(x = species, y = body_mass_g, fill = species)) +\n  geom_boxplot() +\n  labs(title = \"Body Mass by Penguin Species\",\n       x = \"Species\",\n       y = \"Body Mass (g)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](02-data-basics_files/figure-html/unnamed-chunk-9-2.png){fig-align='center' width=100%}\n:::\n\n```{.r .cell-code}\n\n# Scatterplot of bill length vs. flipper length\nggplot(penguins, aes(x = flipper_length_mm, y = bill_length_mm, color = species)) +\n  geom_point(alpha = 0.7) +\n  labs(title = \"Bill Length vs. Flipper Length\",\n       x = \"Flipper Length (mm)\",\n       y = \"Bill Length (mm)\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](02-data-basics_files/figure-html/unnamed-chunk-9-3.png){fig-align='center' width=100%}\n:::\n:::\n\n\n::: {.callout-note}\n## Code Explanation\n\nThis code demonstrates several key data analysis and visualization techniques:\n\n1. **Summary Statistics**:\n   - `summary()` provides descriptive statistics for each variable\n   - Includes min, max, quartiles, mean, and missing values\n\n2. **Correlation Analysis**:\n   - `cor()` calculates correlation coefficients between variables\n   - `select()` chooses specific columns for analysis\n   - `use = \"complete.obs\"` handles missing values\n\n3. **Visualization Components**:\n   - `ggplot()` creates the base plot\n   - `aes()` defines aesthetic mappings\n   - `geom_*()` functions add different plot types\n   - `theme_minimal()` applies a clean theme\n:::\n\n::: {.callout-important}\n## Results Interpretation\n\nThe analysis reveals several important insights:\n\n1. **Variable Distributions**:\n   - Bill lengths show a roughly normal distribution\n   - Body mass varies significantly between species\n   - Some variables have missing values that need attention\n\n2. **Species Differences**:\n   - The boxplot shows clear species-specific body mass patterns\n   - Some species show more variation than others\n   - Potential outliers are visible in the body mass data\n\n3. **Morphological Relationships**:\n   - The scatterplot reveals correlations between bill and flipper lengths\n   - Species clusters are visible in the morphological space\n   - Some species show distinct morphological patterns\n:::\n\n::: {.callout-tip}\n## PROFESSIONAL TIP: Exploratory Data Analysis Best Practices\n\nWhen conducting exploratory data analysis:\n\n1. **Data Quality**:\n   - Always check for missing values first\n   - Look for outliers and potential errors\n   - Verify data types and ranges\n\n2. **Visualization Strategy**:\n   - Start with simple plots (histograms, boxplots)\n   - Progress to more complex visualizations\n   - Use appropriate plot types for your data\n   - Consider colorblind-friendly palettes\n\n3. **Statistical Summary**:\n   - Calculate both descriptive and inferential statistics\n   - Consider the distribution of your data\n   - Look for patterns and relationships\n   - Document any unusual findings\n:::\n\n## Summary\n\nIn this chapter, we've covered the basics of working with data in R:\n\n- Understanding different data types and structures\n- Importing data from various file formats\n- Cleaning and preparing data for analysis\n- Creating new variables\n- Using dplyr for powerful data manipulation\n- Conducting initial exploratory data analysis\n\nThese skills form the foundation for all the analyses we'll perform in the subsequent chapters. By mastering these basics, you'll be well-prepared to tackle more complex analytical challenges in various scientific fields.\n\n## Exercises\n\n1. Load the Palmer Penguins dataset (`../data/environmental/climate_data.csv`) and create a summary of the number of penguins by species and island.\n2. Calculate the mean and standard deviation of bill length, bill depth, and body mass for each penguin species.\n3. Create a new variable that represents the ratio of flipper length to body mass. Interpret what this ratio might represent biologically.\n4. Create a visualization that shows the relationship between bill length and bill depth, colored by species.\n5. Load the crop yields dataset (`../data/agriculture/crop_yields.csv`) and analyze trends in wheat yields over time for a country of your choice.\n6. Compare the distributions of body mass between male and female penguins using appropriate visualizations.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}