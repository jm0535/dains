{
  "hash": "342f5437caf8be406589443a6b6964a7",
  "result": {
    "engine": "knitr",
    "markdown": "---\nprefer-html: true\n---\n\n# Regression Analysis\n\n::: {.callout-note}\n## Learning Objectives\n\nBy the end of this chapter, you will be able to:\n\n1.  Fit and interpret linear and multiple regression models in R\n2.  Check regression assumptions using diagnostic plots\n3.  Implement logistic regression for binary classification\n4.  Apply the `tidymodels` framework for machine learning workflows\n5.  Perform cross-validation to estimate model performance\n6.  Tune hyperparameters to optimize model accuracy\n:::\n\n## Introduction\n\nRegression analysis is a powerful statistical tool for modeling relationships between variables. This chapter explores different types of regression models and their applications in natural sciences research.\n\n## Linear Regression\n\nLinear regression models the relationship between a dependent variable and one or more independent variables:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load required packages\nlibrary(tidyverse)      # For data manipulation\nlibrary(ggplot2)        # For visualization\nlibrary(broom)          # For tidying model outputs\nlibrary(performance)    # For model diagnostics\nlibrary(see)            # For visualization of model diagnostics\nlibrary(parameters)     # For parameter description\nlibrary(ggeffects)      # For visualizing model effects\n\n# Set a professional theme for all plots\ntheme_set(theme_minimal(base_size = 12) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 14),\n    plot.subtitle = element_text(size = 12, color = \"gray40\"),\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    panel.grid.minor = element_blank(),\n    panel.border = element_rect(color = \"gray90\", fill = NA, linewidth = 0.5)\n  ))\n\n# Load the Palmer penguins dataset (stored as climate_data.csv)\npenguins <- read_csv(\"../data/environmental/climate_data.csv\", show_col_types = FALSE)\n\n# Remove rows with missing values in the key variables we'll use for regression\npenguins_clean <- penguins %>%\n  filter(!is.na(bill_length_mm), !is.na(body_mass_g),\n         !is.na(bill_depth_mm), !is.na(flipper_length_mm)) %>%\n  # Add species as a factor for proper modeling\n  mutate(species = as.factor(species))\n\n# Create a linear regression model\nmodel <- lm(body_mass_g ~ bill_length_mm, data = penguins_clean)\n\n# Get model summary with broom for cleaner output\nmodel_summary <- summary(model)\nmodel_tidy <- tidy(model, conf.int = TRUE)\nmodel_glance <- glance(model)\n\n# Display key model metrics\ncat(\"Model Summary:\\n\")\n#> Model Summary:\ncat(paste0(\"R² = \", round(model_glance$r.squared, 3),\n          \", Adjusted R² = \", round(model_glance$adj.r.squared, 3), \"\\n\"))\n#> R² = 0.354, Adjusted R² = 0.352\ncat(paste0(\"F-statistic: \", round(model_glance$statistic, 2),\n          \" on \", model_glance$df, \" and \", model_glance$df.residual,\n          \" DF, p-value: \", format.pval(model_glance$p.value, digits = 3), \"\\n\\n\"))\n#> F-statistic: 186.44 on 1 and 340 DF, p-value: <2e-16\n\n# Create a more professional table of coefficients\nlibrary(gt)\nmodel_tidy %>%\n  gt() %>%\n  tab_header(title = \"Linear Regression Coefficients\") %>%\n  fmt_number(columns = c(\"estimate\", \"std.error\", \"statistic\", \"p.value\", \"conf.low\", \"conf.high\"), decimals = 3)\n```\n\n::: {#fig-linear-regression-intro-1 .cell-output-display}\n\n```{=html}\n<div id=\"pocrojmqlr\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#pocrojmqlr table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#pocrojmqlr thead, #pocrojmqlr tbody, #pocrojmqlr tfoot, #pocrojmqlr tr, #pocrojmqlr td, #pocrojmqlr th {\n  border-style: none;\n}\n\n#pocrojmqlr p {\n  margin: 0;\n  padding: 0;\n}\n\n#pocrojmqlr .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#pocrojmqlr .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#pocrojmqlr .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#pocrojmqlr .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#pocrojmqlr .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pocrojmqlr .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pocrojmqlr .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pocrojmqlr .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#pocrojmqlr .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#pocrojmqlr .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#pocrojmqlr .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#pocrojmqlr .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#pocrojmqlr .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#pocrojmqlr .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#pocrojmqlr .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#pocrojmqlr .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#pocrojmqlr .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#pocrojmqlr .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#pocrojmqlr .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pocrojmqlr .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#pocrojmqlr .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#pocrojmqlr .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#pocrojmqlr .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pocrojmqlr .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#pocrojmqlr .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#pocrojmqlr .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pocrojmqlr .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pocrojmqlr .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#pocrojmqlr .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pocrojmqlr .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#pocrojmqlr .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pocrojmqlr .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pocrojmqlr .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pocrojmqlr .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pocrojmqlr .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pocrojmqlr .gt_left {\n  text-align: left;\n}\n\n#pocrojmqlr .gt_center {\n  text-align: center;\n}\n\n#pocrojmqlr .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#pocrojmqlr .gt_font_normal {\n  font-weight: normal;\n}\n\n#pocrojmqlr .gt_font_bold {\n  font-weight: bold;\n}\n\n#pocrojmqlr .gt_font_italic {\n  font-style: italic;\n}\n\n#pocrojmqlr .gt_super {\n  font-size: 65%;\n}\n\n#pocrojmqlr .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#pocrojmqlr .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#pocrojmqlr .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#pocrojmqlr .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#pocrojmqlr .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#pocrojmqlr .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#pocrojmqlr .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#pocrojmqlr .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#pocrojmqlr div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_heading\">\n      <td colspan=\"7\" class=\"gt_heading gt_title gt_font_normal gt_bottom_border\" style>Linear Regression Coefficients</td>\n    </tr>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"term\">term</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"estimate\">estimate</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"std.error\">std.error</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"statistic\">statistic</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"p.value\">p.value</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"conf.low\">conf.low</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"conf.high\">conf.high</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"term\" class=\"gt_row gt_left\">(Intercept)</td>\n<td headers=\"estimate\" class=\"gt_row gt_right\">362.307</td>\n<td headers=\"std.error\" class=\"gt_row gt_right\">283.345</td>\n<td headers=\"statistic\" class=\"gt_row gt_right\">1.279</td>\n<td headers=\"p.value\" class=\"gt_row gt_right\">0.202</td>\n<td headers=\"conf.low\" class=\"gt_row gt_right\">−195.024</td>\n<td headers=\"conf.high\" class=\"gt_row gt_right\">919.637</td></tr>\n    <tr><td headers=\"term\" class=\"gt_row gt_left\">bill_length_mm</td>\n<td headers=\"estimate\" class=\"gt_row gt_right\">87.415</td>\n<td headers=\"std.error\" class=\"gt_row gt_right\">6.402</td>\n<td headers=\"statistic\" class=\"gt_row gt_right\">13.654</td>\n<td headers=\"p.value\" class=\"gt_row gt_right\">0.000</td>\n<td headers=\"conf.low\" class=\"gt_row gt_right\">74.823</td>\n<td headers=\"conf.high\" class=\"gt_row gt_right\">100.008</td></tr>\n  </tbody>\n  \n</table>\n</div>\n```\n\n\nRelationship between bill length and body mass\n:::\n\n```{.r .cell-code}\n\n# Create an enhanced scatter plot with regression line\nggplot(penguins_clean, aes(x = bill_length_mm, y = body_mass_g)) +\n  # Add data points with some transparency\n  geom_point(aes(color = species), alpha = 0.7, size = 3) +\n  # Add regression line with confidence interval\n  geom_smooth(method = \"lm\", color = \"darkred\", fill = \"pink\", alpha = 0.2) +\n  # Add annotations for R² and p-value\n  annotate(\"text\", x = min(penguins_clean$bill_length_mm) + 1,\n           y = max(penguins_clean$body_mass_g) - 500,\n           label = paste0(\"R² = \", round(model_glance$r.squared, 3),\n                         \"\\np < \", format.pval(model_glance$p.value, digits = 3)),\n           hjust = 0, size = 4, color = \"darkred\") +\n  # Add regression equation\n  annotate(\"text\", x = min(penguins_clean$bill_length_mm) + 1,\n           y = max(penguins_clean$body_mass_g) - 1000,\n           label = paste0(\"y = \", round(coef(model)[1], 1), \" + \",\n                         round(coef(model)[2], 1), \"x\"),\n           hjust = 0, size = 4, color = \"darkred\") +\n  # Add professional labels\n  labs(\n    title = \"Relationship Between Bill Length and Body Mass\",\n    subtitle = \"Linear regression analysis shows positive correlation with species differences\",\n    x = \"Bill Length (mm)\",\n    y = \"Body Mass (g)\",\n    color = \"Species\",\n    caption = \"Data source: Palmer Penguins dataset\"\n  ) +\n  # Use a colorblind-friendly palette\n  scale_color_viridis_d() +\n  # Adjust axis limits for better visualization\n  coord_cartesian(expand = TRUE)\n\n# Create diagnostic plots using the performance package\ncheck_model <- check_model(model)\nplot(check_model)\n\n# Create additional diagnostic plots for specific issues\npar(mfrow = c(2, 2))\nplot(model)\n```\n\n::: {.cell-output-display}\n![Relationship between bill length and body mass](08-regression_files/figure-html/fig-linear-regression-intro-1.png){#fig-linear-regression-intro-2 fig-align='center' width=100%}\n:::\n\n::: {.cell-output-display}\n![Model diagnostic plots](08-regression_files/figure-html/fig-linear-regression-intro-2.png){#fig-linear-regression-intro-3 fig-align='center' width=100%}\n:::\n\n::: {.cell-output-display}\n![Relationship between bill length and body mass](08-regression_files/figure-html/fig-linear-regression-intro-3.png){#fig-linear-regression-intro-4 fig-align='center' width=100%}\n:::\n:::\n\n\n::: {.callout-note}\n## Code Explanation\n\nThis code demonstrates linear regression analysis:\n\n1. **Model Setup**:\n   - Uses `lm()` for linear regression\n   - Predicts body mass from bill length\n   - Includes model diagnostics\n\n2. **Visualization**:\n   - Creates scatter plot with regression line\n   - Uses `geom_smooth()` for trend line\n   - Adds appropriate labels\n\n3. **Diagnostics**:\n   - Residual plots\n   - Q-Q plot\n   - Scale-location plot\n   - Leverage plot\n:::\n\n::: {.callout-important}\n## Results Interpretation\n\nThe regression analysis reveals:\n\n1. **Model Fit**:\n   - Strength of relationship (R²)\n   - Statistical significance (p-value)\n   - Direction of relationship\n\n2. **Assumptions**:\n   - Linearity of relationship\n   - Homogeneity of variance\n   - Normality of residuals\n   - Independence of observations\n\n3. **Practical Significance**:\n   - Effect size\n   - Biological relevance\n   - Prediction accuracy\n:::\n\n::: {.callout-tip}\n## PROFESSIONAL TIP: Regression Analysis Best Practices\n\nWhen conducting regression analysis:\n\n1. **Model Selection**:\n   - Choose appropriate model type\n   - Consider variable transformations\n   - Check for multicollinearity\n   - Evaluate model assumptions\n\n2. **Diagnostic Checks**:\n   - Examine residual plots\n   - Check for outliers\n   - Verify normality\n   - Assess leverage points\n\n3. **Reporting**:\n   - Include model coefficients\n   - Report confidence intervals\n   - Provide effect sizes\n   - Discuss limitations\n:::\n\n## Multiple Regression\n\nMultiple regression extends linear regression to include multiple predictors:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load required packages\nlibrary(broom)\nlibrary(knitr)\nlibrary(dplyr)\n\n# Create multiple regression model\nmulti_model <- lm(body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + species,\n                 data = penguins_clean)\n\n# Get model summary with broom for cleaner output\nmulti_summary <- summary(multi_model)\nmulti_tidy <- tidy(multi_model, conf.int = TRUE)\nmulti_glance <- glance(multi_model)\n\n# Display key model metrics\ncat(\"Multiple Regression Model Summary:\\n\")\n#> Multiple Regression Model Summary:\ncat(paste0(\"R² = \", round(multi_glance$r.squared, 3),\n          \", Adjusted R² = \", round(multi_glance$adj.r.squared, 3), \"\\n\"))\n#> R² = 0.847, Adjusted R² = 0.845\ncat(paste0(\"F-statistic: \", round(multi_glance$statistic, 2),\n          \" on \", multi_glance$df, \" and \", multi_glance$df.residual,\n          \" DF, p-value: \", format.pval(multi_glance$p.value, digits = 3), \"\\n\\n\"))\n#> F-statistic: 372.37 on 5 and 336 DF, p-value: <2e-16\n\n# Create a simple table of coefficients\nprint(multi_tidy)\n#> # A tibble: 6 × 7\n#>   term              estimate std.error statistic  p.value conf.low conf.high\n#>   <chr>                <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n#> 1 (Intercept)        -4327.     495.       -8.74 1.09e-16  -5301.    -3354. \n#> 2 bill_length_mm        41.5      7.16      5.79 1.62e- 8     27.4      55.6\n#> 3 bill_depth_mm        140.      19.0       7.40 1.14e-12    103.      178. \n#> 4 flipper_length_mm     20.2      3.11      6.52 2.61e-10     14.1      26.3\n#> 5 speciesChinstrap    -513.      82.1      -6.25 1.25e- 9   -675.     -352. \n#> 6 speciesGentoo        935.     141.        6.64 1.26e-10    658.     1212.\n\n# Check for multicollinearity\nlibrary(car)\nvif_values <- car::vif(multi_model)\nknitr::kable(vif_values, digits = 3,\n             caption = \"Variance Inflation Factors (VIF)\")\n```\n\n::: {#fig-multiple-regression-1 .cell-output-display}\n\n\nTable: Variance Inflation Factors (VIF)\n\n|                  |   GVIF| Df| GVIF^(1/(2*Df))|\n|:-----------------|------:|--:|---------------:|\n|bill_length_mm    |  5.226|  1|           2.286|\n|bill_depth_mm     |  4.799|  1|           2.191|\n|flipper_length_mm |  6.516|  1|           2.553|\n|species           | 34.117|  2|           2.417|\n\n\n\nMultiple regression diagnostic plots\n:::\n\n```{.r .cell-code}\n\n# Check for model assumptions\ncheck_multi_model <- check_model(multi_model)\nplot(check_multi_model)\n\n# Visualize predictor effects\nlibrary(effects)\nplot(allEffects(multi_model), ask = FALSE)\n\n# Compare models using base R\nmodel_comparison <- data.frame(\n  Metric = c(\"R²\", \"Adjusted R²\", \"AIC\", \"BIC\", \"N\"),\n  `Simple Model` = c(\n    round(summary(model)$r.squared, 3),\n    round(summary(model)$adj.r.squared, 3),\n    round(AIC(model), 1),\n    round(BIC(model), 1),\n    nobs(model)\n  ),\n  `Multiple Model` = c(\n    round(summary(multi_model)$r.squared, 3),\n    round(summary(multi_model)$adj.r.squared, 3),\n    round(AIC(multi_model), 1),\n    round(BIC(multi_model), 1),\n    nobs(multi_model)\n  ),\n  check.names = FALSE\n)\nknitr::kable(model_comparison, caption = \"Comparison of Regression Models\")\n```\n\n::: {#fig-multiple-regression-2 .cell-output-display}\n\n\nTable: Comparison of Regression Models\n\n|Metric      | Simple Model| Multiple Model|\n|:-----------|------------:|--------------:|\n|R²          |        0.354|          0.847|\n|Adjusted R² |        0.352|          0.845|\n|AIC         |     5400.000|       4915.200|\n|BIC         |     5411.500|       4942.000|\n|N           |      342.000|        342.000|\n\n\n\nMultiple regression diagnostic plots\n:::\n\n```{.r .cell-code}\n\n# Create a visualization of predicted vs. actual values\npredicted_values <- augment(multi_model, data = penguins_clean)\n\nggplot(predicted_values, aes(x = .fitted, y = body_mass_g, color = species)) +\n  geom_point(size = 3, alpha = 0.7) +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"gray50\") +\n  labs(\n    title = \"Predicted vs. Actual Body Mass\",\n    subtitle = \"Points closer to the dashed line indicate better predictions\",\n    x = \"Predicted Body Mass (g)\",\n    y = \"Actual Body Mass (g)\",\n    color = \"Species\",\n    caption = \"Model: body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + species\"\n  ) +\n  scale_color_viridis_d() +\n  theme(legend.position = \"bottom\")\n\n# Create a partial dependence plot for flipper length\npdp_flipper <- ggeffects::ggpredict(multi_model, terms = \"flipper_length_mm\")\nplot(pdp_flipper) +\n  labs(\n    title = \"Effect of Flipper Length on Body Mass\",\n    subtitle = \"Controlling for other variables in the model\",\n    caption = \"Shaded area represents 95% confidence interval\"\n  )\n```\n\n::: {.cell-output-display}\n![Multiple regression diagnostic plots](08-regression_files/figure-html/fig-multiple-regression-1.png){#fig-multiple-regression-3 fig-align='center' width=100%}\n:::\n\n::: {.cell-output-display}\n![Predicted vs actual body mass](08-regression_files/figure-html/fig-multiple-regression-2.png){#fig-multiple-regression-4 fig-align='center' width=100%}\n:::\n\n::: {.cell-output-display}\n![Effect of flipper length on body mass](08-regression_files/figure-html/fig-multiple-regression-3.png){#fig-multiple-regression-5 fig-align='center' width=100%}\n:::\n\n::: {.cell-output-display}\n![Multiple regression diagnostic plots](08-regression_files/figure-html/fig-multiple-regression-4.png){#fig-multiple-regression-6 fig-align='center' width=100%}\n:::\n:::\n\n\n::: {.callout-note}\n## Code Explanation\n\nThis code demonstrates enhanced multiple regression analysis techniques:\n\n1. **Model Construction**\n   - Uses `lm()` to build a multiple regression with morphological predictors and species\n   - Creates a more comprehensive model accounting for both measurements and taxonomy\n   - Properly handles categorical predictors (species) with appropriate contrasts\n\n2. **Advanced Diagnostics**\n   - Evaluates multicollinearity with Variance Inflation Factors (VIF)\n   - Conducts comprehensive model assumption checks\n   - Compares model performance metrics across simple and multiple regression\n\n3. **Professional Visualization**\n   - Creates an elegant predicted vs. actual plot to assess model fit\n   - Generates partial dependence plots to visualize individual predictor effects\n   - Uses model effects plots to show relationships while controlling for other variables\n   - Implements consistent styling with appropriate annotations and colorblind-friendly palettes\n:::\n\n::: {.callout-important}\n## Results Interpretation\n\nThe multiple regression analysis reveals several important insights:\n\n1. **Model Performance**\n   - Multiple regression substantially improves explanatory power over simple regression\n   - The adjusted R² is much higher, indicating better model fit\n   - Species is a significant predictor, suggesting morphological differences between species\n\n2. **Predictor Effects**\n   - Flipper length and bill length both positively correlate with body mass\n   - Species-specific effects indicate evolutionary differences in body size\n   - Bill depth shows a weaker relationship when controlling for other variables\n\n3. **Diagnostics Findings**\n   - Multicollinearity (VIF values) appears manageable (VIF < 5 is generally acceptable)\n   - The model generally meets assumptions for inference\n   - Residual patterns suggest the linear model captures the main relationships well\n:::\n\n::: {.callout-tip}\n## PROFESSIONAL TIP: Multiple Regression Best Practices\n\nWhen conducting ecological multiple regression analyses:\n\n1. **Model Building Strategy**\n   - Start with biologically meaningful predictors based on theory\n   - Consider alternative model specifications (linear, polynomial, interactions)\n   - Use a hierarchical approach, starting simple and adding complexity\n   - Adopt information-theoretic approaches (AIC/BIC) for model selection\n\n2. **Addressing Collinearity**\n   - Examine correlations among predictors before modeling\n   - Calculate VIF values and remove highly collinear predictors (VIF > 10)\n   - Consider dimension reduction techniques (PCA) for related predictors\n   - Use regularization methods (ridge, lasso) for high-dimensional data\n\n3. **Results Communication**\n   - Present standardized coefficients to compare predictor importance\n   - Visualize partial effects rather than just reporting coefficients\n   - Report effect sizes and confidence intervals, not just p-values\n   - Describe both statistical and biological significance of your findings\n:::\n\n## Logistic Regression\n\nLogistic regression models binary outcomes:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Prepare data for logistic regression by creating a binary outcome\n# We'll predict whether a penguin is Adelie species or not\npenguins_binary <- penguins_clean %>%\n  # Create a binary outcome variable (is_adelie)\n  mutate(is_adelie = ifelse(species == \"Adelie\", 1, 0),\n         # Convert to factor for better model interpretation\n         is_adelie_factor = factor(is_adelie, levels = c(0, 1),\n                                  labels = c(\"Other\", \"Adelie\")))\n\n# Create logistic regression model\nlog_model <- glm(is_adelie ~ bill_length_mm + bill_depth_mm + flipper_length_mm,\n                family = binomial(link = \"logit\"),\n                data = penguins_binary)\n\n# Summarize model with tidy output\nlog_summary <- summary(log_model)\nlog_tidy <- tidy(log_model, conf.int = TRUE, exponentiate = TRUE)\nlog_glance <- glance(log_model)\n\n# Display key model metrics\ncat(\"Logistic Regression Model Summary:\\n\")\n#> Logistic Regression Model Summary:\ncat(paste0(\"AIC: \", round(log_glance$AIC, 2),\n          \", Deviance: \", round(log_glance$deviance, 2), \"\\n\"))\n#> AIC: 23.62, Deviance: 15.62\ncat(paste0(\"Null Deviance: \", round(log_glance$null.deviance, 2),\n          \", DF: \", log_glance$df.null, \", Residual DF: \", log_glance$df.residual, \"\\n\\n\"))\n#> Null Deviance: 469.42, DF: 341, Residual DF: 338\n\n# Calculate and show pseudo R-squared (McFadden)\npseudo_r2 <- 1 - (log_glance$deviance / log_glance$null.deviance)\ncat(paste0(\"McFadden's Pseudo R²: \", round(pseudo_r2, 3), \"\\n\\n\"))\n#> McFadden's Pseudo R²: 0.967\n\n# Create a table of odds ratios with CI\nlog_tidy %>%\n  gt() %>%\n  tab_header(title = \"Logistic Regression Results (Odds Ratios)\") %>%\n  fmt_number(columns = c(\"estimate\", \"std.error\", \"statistic\", \"p.value\", \"conf.low\", \"conf.high\"), decimals = 3)\n```\n\n::: {#fig-logistic-regression-1 .cell-output-display}\n\n```{=html}\n<div id=\"nmyqtnnghh\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#nmyqtnnghh table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#nmyqtnnghh thead, #nmyqtnnghh tbody, #nmyqtnnghh tfoot, #nmyqtnnghh tr, #nmyqtnnghh td, #nmyqtnnghh th {\n  border-style: none;\n}\n\n#nmyqtnnghh p {\n  margin: 0;\n  padding: 0;\n}\n\n#nmyqtnnghh .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#nmyqtnnghh .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#nmyqtnnghh .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#nmyqtnnghh .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#nmyqtnnghh .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#nmyqtnnghh .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#nmyqtnnghh .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#nmyqtnnghh .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#nmyqtnnghh .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#nmyqtnnghh .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#nmyqtnnghh .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#nmyqtnnghh .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#nmyqtnnghh .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#nmyqtnnghh .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#nmyqtnnghh .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#nmyqtnnghh .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#nmyqtnnghh .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#nmyqtnnghh .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#nmyqtnnghh .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#nmyqtnnghh .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#nmyqtnnghh .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#nmyqtnnghh .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#nmyqtnnghh .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#nmyqtnnghh .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#nmyqtnnghh .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#nmyqtnnghh .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#nmyqtnnghh .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#nmyqtnnghh .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#nmyqtnnghh .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#nmyqtnnghh .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#nmyqtnnghh .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#nmyqtnnghh .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#nmyqtnnghh .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#nmyqtnnghh .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#nmyqtnnghh .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#nmyqtnnghh .gt_left {\n  text-align: left;\n}\n\n#nmyqtnnghh .gt_center {\n  text-align: center;\n}\n\n#nmyqtnnghh .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#nmyqtnnghh .gt_font_normal {\n  font-weight: normal;\n}\n\n#nmyqtnnghh .gt_font_bold {\n  font-weight: bold;\n}\n\n#nmyqtnnghh .gt_font_italic {\n  font-style: italic;\n}\n\n#nmyqtnnghh .gt_super {\n  font-size: 65%;\n}\n\n#nmyqtnnghh .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#nmyqtnnghh .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#nmyqtnnghh .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#nmyqtnnghh .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#nmyqtnnghh .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#nmyqtnnghh .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#nmyqtnnghh .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#nmyqtnnghh .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#nmyqtnnghh div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_heading\">\n      <td colspan=\"7\" class=\"gt_heading gt_title gt_font_normal gt_bottom_border\" style>Logistic Regression Results (Odds Ratios)</td>\n    </tr>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"term\">term</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"estimate\">estimate</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"std.error\">std.error</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"statistic\">statistic</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"p.value\">p.value</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"conf.low\">conf.low</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"conf.high\">conf.high</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"term\" class=\"gt_row gt_left\">(Intercept)</td>\n<td headers=\"estimate\" class=\"gt_row gt_right\">44,448.176</td>\n<td headers=\"std.error\" class=\"gt_row gt_right\">15.855</td>\n<td headers=\"statistic\" class=\"gt_row gt_right\">0.675</td>\n<td headers=\"p.value\" class=\"gt_row gt_right\">0.500</td>\n<td headers=\"conf.low\" class=\"gt_row gt_right\">0.000</td>\n<td headers=\"conf.high\" class=\"gt_row gt_right\">92,511,770,940,489,252,864.000</td></tr>\n    <tr><td headers=\"term\" class=\"gt_row gt_left\">bill_length_mm</td>\n<td headers=\"estimate\" class=\"gt_row gt_right\">0.059</td>\n<td headers=\"std.error\" class=\"gt_row gt_right\">0.970</td>\n<td headers=\"statistic\" class=\"gt_row gt_right\">−2.925</td>\n<td headers=\"p.value\" class=\"gt_row gt_right\">0.003</td>\n<td headers=\"conf.low\" class=\"gt_row gt_right\">0.004</td>\n<td headers=\"conf.high\" class=\"gt_row gt_right\">0.224</td></tr>\n    <tr><td headers=\"term\" class=\"gt_row gt_left\">bill_depth_mm</td>\n<td headers=\"estimate\" class=\"gt_row gt_right\">101.769</td>\n<td headers=\"std.error\" class=\"gt_row gt_right\">1.754</td>\n<td headers=\"statistic\" class=\"gt_row gt_right\">2.635</td>\n<td headers=\"p.value\" class=\"gt_row gt_right\">0.008</td>\n<td headers=\"conf.low\" class=\"gt_row gt_right\">8.824</td>\n<td headers=\"conf.high\" class=\"gt_row gt_right\">10,709.177</td></tr>\n    <tr><td headers=\"term\" class=\"gt_row gt_left\">flipper_length_mm</td>\n<td headers=\"estimate\" class=\"gt_row gt_right\">1.164</td>\n<td headers=\"std.error\" class=\"gt_row gt_right\">0.094</td>\n<td headers=\"statistic\" class=\"gt_row gt_right\">1.616</td>\n<td headers=\"p.value\" class=\"gt_row gt_right\">0.106</td>\n<td headers=\"conf.low\" class=\"gt_row gt_right\">0.983</td>\n<td headers=\"conf.high\" class=\"gt_row gt_right\">1.467</td></tr>\n  </tbody>\n  \n</table>\n</div>\n```\n\n\nROC curve for Adelie penguin classification\n:::\n\n```{.r .cell-code}\n\n# Add predictions to the data\npenguins_pred <- penguins_binary %>%\n  mutate(\n    predicted_prob = predict(log_model, type = \"response\"),\n    predicted_class = ifelse(predicted_prob > 0.5, \"Adelie\", \"Other\"),\n    correct = ifelse(predicted_class == ifelse(is_adelie == 1, \"Adelie\", \"Other\"), \"Correct\", \"Incorrect\")\n  )\n\n# Create a confusion matrix\nconfusion <- table(\n  Predicted = penguins_pred$predicted_class,\n  Actual = ifelse(penguins_pred$is_adelie == 1, \"Adelie\", \"Other\")\n)\n\n# Calculate accuracy metrics\naccuracy <- sum(diag(confusion)) / sum(confusion)\nsensitivity <- confusion[\"Adelie\", \"Adelie\"] / sum(confusion[, \"Adelie\"])\nspecificity <- confusion[\"Other\", \"Other\"] / sum(confusion[, \"Other\"])\nprecision <- confusion[\"Adelie\", \"Adelie\"] / sum(confusion[\"Adelie\", ])\n\n# Display confusion matrix with metrics\nknitr::kable(confusion,\n            caption = paste0(\"Confusion Matrix (Accuracy = \", round(accuracy * 100, 1), \"%)\"))\n```\n\n::: {#fig-logistic-regression-2 .cell-output-display}\n\n\nTable: Confusion Matrix (Accuracy = 99.1%)\n\n|       | Adelie| Other|\n|:------|------:|-----:|\n|Adelie |    150|     2|\n|Other  |      1|   189|\n\n\n\nROC curve for Adelie penguin classification\n:::\n\n```{.r .cell-code}\n\ncat(paste0(\"Sensitivity (True Positive Rate): \", round(sensitivity * 100, 1), \"%\\n\"))\n#> Sensitivity (True Positive Rate): 99.3%\ncat(paste0(\"Specificity (True Negative Rate): \", round(specificity * 100, 1), \"%\\n\"))\n#> Specificity (True Negative Rate): 99%\ncat(paste0(\"Precision (Positive Predictive Value): \", round(precision * 100, 1), \"%\\n\\n\"))\n#> Precision (Positive Predictive Value): 98.7%\n\n# Create ROC curve\nlibrary(pROC)\nroc_curve <- roc(penguins_binary$is_adelie, fitted(log_model))\nauc_value <- auc(roc_curve)\n\n# Plot the ROC curve\nplot(roc_curve, print.auc = TRUE, auc.polygon = TRUE,\n     grid = TRUE, main = \"ROC Curve for Adelie Penguin Classification\")\n\n# Create a visualization of predicted probabilities by species\nggplot(penguins_pred, aes(x = bill_length_mm, y = bill_depth_mm, color = predicted_prob)) +\n  geom_point(size = 3, alpha = 0.7) +\n  # Add decision boundary (0.5 probability contour)\n  geom_contour(aes(z = predicted_prob), breaks = 0.5, color = \"black\", linewidth = 1) +\n  # Add text labels for misclassified points\n  geom_text(data = filter(penguins_pred, correct == \"Incorrect\"),\n            aes(label = \"✗\"), color = \"black\", size = 4, nudge_y = 0.5) +\n  # Color gradient for probability\n  scale_color_gradient2(low = \"navy\", mid = \"white\", high = \"red\",\n                      midpoint = 0.5, limits = c(0, 1)) +\n  facet_wrap(~species) +\n  labs(\n    title = \"Classification of Adelie vs. Other Penguins\",\n    subtitle = paste0(\"AUC = \", round(auc_value, 3), \", Accuracy = \", round(accuracy * 100, 1), \"%\"),\n    x = \"Bill Length (mm)\",\n    y = \"Bill Depth (mm)\",\n    color = \"Probability\\nof Adelie\",\n    caption = \"Black line: decision boundary (p=0.5), ✗: misclassified points\"\n  ) +\n  theme(legend.position = \"right\")\n\n# Create marginal effects plots for the predictors\nlibrary(effects)\nplot(allEffects(log_model), ask = FALSE, main = \"Marginal Effects on Probability of Adelie\")\n\n# Check model fit\nlibrary(DHARMa)\nsim_residuals <- simulateResiduals(log_model)\nplot(sim_residuals)\n```\n\n::: {.cell-output-display}\n![ROC curve for Adelie penguin classification](08-regression_files/figure-html/fig-logistic-regression-1.png){#fig-logistic-regression-3 fig-align='center' width=100%}\n:::\n\n::: {.cell-output-display}\n![Classification visualization by species](08-regression_files/figure-html/fig-logistic-regression-2.png){#fig-logistic-regression-4 fig-align='center' width=100%}\n:::\n\n::: {.cell-output-display}\n![Marginal effects on probability](08-regression_files/figure-html/fig-logistic-regression-3.png){#fig-logistic-regression-5 fig-align='center' width=100%}\n:::\n\n::: {.cell-output-display}\n![DHARMa residual diagnostics](08-regression_files/figure-html/fig-logistic-regression-4.png){#fig-logistic-regression-6 fig-align='center' width=100%}\n:::\n:::\n\n\n::: {.callout-note}\n## Code Explanation\n\nThis enhanced logistic regression analysis provides comprehensive insights:\n\n1. **Model Construction**\n   - Creates a binary outcome variable (Adelie vs. Other species)\n   - Uses `glm()` with a binomial family and logit link\n   - Incorporates multiple predictors (bill length, bill depth, flipper length)\n\n2. **Professional Reporting**\n   - Displays odds ratios with confidence intervals for interpretability\n   - Calculates and reports pseudo-R² (McFadden) for model fit\n   - Creates a detailed confusion matrix with classification metrics\n   - Generates a ROC curve with AUC for overall discriminative ability\n\n3. **Advanced Visualization**\n   - Plots predicted probabilities with decision boundaries\n   - Highlights misclassified points for error analysis\n   - Creates marginal effects plots showing how each predictor influences classification\n   - Conducts simulation-based residual analysis for model validation\n:::\n\n::: {.callout-important}\n## Results Interpretation\n\nThe logistic regression yields important ecological insights:\n\n1. **Classification Performance**\n   - The model effectively distinguishes Adelie penguins from other species\n   - High AUC (area under ROC curve) indicates strong discriminative ability\n   - Classification accuracy, sensitivity, and specificity show the practical utility\n\n2. **Morphological Predictors**\n   - Bill dimensions are strong predictors of species identity\n   - Odds ratios reveal how changes in morphology affect classification probability\n   - Interaction between bill length and depth creates a clear decision boundary\n\n3. **Ecological Implications**\n   - The model demonstrates morphological differentiation between penguin species\n   - Misclassified individuals may represent morphological overlap zones\n   - Results align with evolutionary theory on character displacement\n   - Potential applications in field identification and evolutionary studies\n:::\n\n::: {.callout-tip}\n## PROFESSIONAL TIP: Logistic Regression Best Practices\n\nWhen applying logistic regression in ecological studies:\n\n1. **Model Development**\n   - Balance the number of events and predictors (aim for >10 events per predictor)\n   - Test for nonlinearity in continuous predictors using splines or polynomial terms\n   - Evaluate interactions between predictors where biologically meaningful\n   - Consider regularization for high-dimensional data to prevent overfitting\n\n2. **Model Evaluation**\n   - Use cross-validation to assess predictive performance\n   - Report multiple performance metrics beyond p-values (AUC, accuracy, sensitivity, specificity)\n   - Consider the costs of different error types (false positives vs. false negatives)\n   - Test model calibration (agreement between predicted probabilities and observed outcomes)\n\n3. **Result Communication**\n   - Report odds ratios for interpretability (not just coefficients)\n   - Create visualizations showing decision boundaries and classification regions\n   - Discuss practical significance for ecological applications\n   - Indicate model limitations and potential sampling biases\n:::\n\n## Summary\n\nIn this chapter, we've explored regression analysis using both traditional base R approaches and the modern tidymodels framework:\n\n- **Linear regression** for modeling continuous relationships between morphological variables\n- **Multiple regression** for incorporating several predictors and controlling for confounding factors\n- **Logistic regression** for binary classification and probability estimation\n- **Tidymodels workflow** for consistent, reproducible modeling\n\nThe tidymodels framework provides:\n- Unified interface across different model types\n- Consistent preprocessing with recipes\n- Built-in resampling and cross-validation\n- Standardized model evaluation metrics\n- Streamlined workflow management\n\nEach approach provides unique insights into ecological patterns and relationships, with applications ranging from morphological studies to species classification and trait prediction.\n\n## Regression with Tidymodels Framework\n\nThe tidymodels ecosystem provides a modern, unified approach to statistical modeling in R. Let's explore how to implement regression analysis using this framework.\n\n### Setting Up Tidymodels\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load tidymodels packages\nlibrary(tidymodels)  # Meta-package loading parsnip, recipes, rsample, tune, workflows, yardstick\nlibrary(tidyverse)    # For data manipulation\n\n# Set random seed for reproducibility\nset.seed(123)\n\n# Load and prepare data\npenguins <- read_csv(\"../data/environmental/climate_data.csv\", show_col_types = FALSE) %>%\n  filter(!is.na(bill_length_mm), !is.na(body_mass_g),\n         !is.na(bill_depth_mm), !is.na(flipper_length_mm)) %>%\n  mutate(species = as.factor(species))\n\n# Display data structure\nglimpse(penguins)\n#> Rows: 342\n#> Columns: 8\n#> $ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n#> $ island            <chr> \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen\", …\n#> $ bill_length_mm    <dbl> 39.1, 39.5, 40.3, 36.7, 39.3, 38.9, 39.2, 34.1, 42.0…\n#> $ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, 19.3, 20.6, 17.8, 19.6, 18.1, 20.2…\n#> $ flipper_length_mm <dbl> 181, 186, 195, 193, 190, 181, 195, 193, 190, 186, 18…\n#> $ body_mass_g       <dbl> 3750, 3800, 3250, 3450, 3650, 3625, 4675, 3475, 4250…\n#> $ sex               <chr> \"male\", \"female\", \"female\", \"female\", \"male\", \"femal…\n#> $ year              <dbl> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n```\n:::\n\n\n::: {.callout-note}\n## Tidymodels Philosophy\n\nThe tidymodels framework follows key principles:\n\n1. **Consistency**: Uniform syntax across different model types\n2. **Modularity**: Separate components for different modeling tasks\n3. **Tidyverse integration**: Works seamlessly with dplyr, ggplot2, etc.\n4. **Reproducibility**: Built-in support for resampling and validation\n5. **Extensibility**: Easy to add new models and methods\n:::\n\n### Linear Regression with Tidymodels\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Step 1: Split data into training and testing sets\npenguin_split <- initial_split(penguins, prop = 0.75, strata = species)\npenguin_train <- training(penguin_split)\npenguin_test <- testing(penguin_split)\n\ncat(\"Training set:\", nrow(penguin_train), \"observations\\n\")\n#> Training set: 256 observations\ncat(\"Testing set:\", nrow(penguin_test), \"observations\\n\")\n#> Testing set: 86 observations\n\n# Step 2: Define a recipe for preprocessing\npenguin_recipe <- recipe(body_mass_g ~ bill_length_mm + bill_depth_mm +\n                         flipper_length_mm + species,\n                         data = penguin_train) %>%\n  # Create dummy variables for species\n  step_dummy(species) %>%\n  # Normalize all numeric predictors\n  step_normalize(all_numeric_predictors()) %>%\n  # Check for zero variance predictors\n  step_zv(all_predictors())\n\n# View the recipe\nprint(penguin_recipe)\n\n# Step 3: Specify the model\nlm_spec <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  set_mode(\"regression\")\n\nprint(lm_spec)\n#> Linear Regression Model Specification (regression)\n#> \n#> Computational engine: lm\n\n# Step 4: Create a workflow combining recipe and model\npenguin_wf <- workflow() %>%\n  add_recipe(penguin_recipe) %>%\n  add_model(lm_spec)\n\nprint(penguin_wf)\n#> ══ Workflow ════════════════════════════════════════════════════════════════════\n#> Preprocessor: Recipe\n#> Model: linear_reg()\n#> \n#> ── Preprocessor ────────────────────────────────────────────────────────────────\n#> 3 Recipe Steps\n#> \n#> • step_dummy()\n#> • step_normalize()\n#> • step_zv()\n#> \n#> ── Model ───────────────────────────────────────────────────────────────────────\n#> Linear Regression Model Specification (regression)\n#> \n#> Computational engine: lm\n\n# Step 5: Fit the model\npenguin_fit <- penguin_wf %>%\n  fit(data = penguin_train)\n\n# Extract and display model results\ntidy(penguin_fit) %>%\n  knitr::kable(caption = \"Tidymodels Linear Regression Coefficients\",\n               digits = 3)\n```\n\n::: {#fig-tidymodels-linear-1 .cell-output-display}\n\n\nTable: Tidymodels Linear Regression Coefficients\n\n|term              | estimate| std.error| statistic| p.value|\n|:-----------------|--------:|---------:|---------:|-------:|\n|(Intercept)       | 4191.992|    20.678|   202.725|       0|\n|bill_length_mm    |  267.541|    50.646|     5.283|       0|\n|bill_depth_mm     |  278.664|    46.447|     6.000|       0|\n|flipper_length_mm |  243.626|    53.809|     4.528|       0|\n|species_Chinstrap | -236.669|    42.184|    -5.610|       0|\n|species_Gentoo    |  450.673|    82.451|     5.466|       0|\n\n\n\nTidymodels predicted vs actual body mass\n:::\n\n```{.r .cell-code}\n\n# Get model performance metrics on training data\ntrain_results <- penguin_fit %>%\n  predict(penguin_train) %>%\n  bind_cols(penguin_train) %>%\n  metrics(truth = body_mass_g, estimate = .pred)\n\nknitr::kable(train_results,\n             caption = \"Training Set Performance Metrics\",\n             digits = 3)\n```\n\n::: {#fig-tidymodels-linear-2 .cell-output-display}\n\n\nTable: Training Set Performance Metrics\n\n|.metric |.estimator | .estimate|\n|:-------|:----------|---------:|\n|rmse    |standard   |   326.952|\n|rsq     |standard   |     0.832|\n|mae     |standard   |   260.412|\n\n\n\nTidymodels predicted vs actual body mass\n:::\n\n```{.r .cell-code}\n\n# Step 6: Evaluate on test data\ntest_results <- penguin_fit %>%\n  predict(penguin_test) %>%\n  bind_cols(penguin_test) %>%\n  metrics(truth = body_mass_g, estimate = .pred)\n\nknitr::kable(test_results,\n             caption = \"Test Set Performance Metrics\",\n             digits = 3)\n```\n\n::: {#fig-tidymodels-linear-3 .cell-output-display}\n\n\nTable: Test Set Performance Metrics\n\n|.metric |.estimator | .estimate|\n|:-------|:----------|---------:|\n|rmse    |standard   |   272.490|\n|rsq     |standard   |     0.888|\n|mae     |standard   |   216.419|\n\n\n\nTidymodels predicted vs actual body mass\n:::\n\n```{.r .cell-code}\n\n# Create predictions for visualization\npenguin_pred <- penguin_fit %>%\n  predict(penguin_test) %>%\n  bind_cols(penguin_test)\n\n# Visualize predictions vs. actual\nggplot(penguin_pred, aes(x = body_mass_g, y = .pred, color = species)) +\n  geom_point(size = 3, alpha = 0.7) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray50\") +\n  scale_color_viridis_d() +\n  labs(\n    title = \"Tidymodels: Predicted vs. Actual Body Mass\",\n    subtitle = \"Test set predictions from linear regression workflow\",\n    x = \"Actual Body Mass (g)\",\n    y = \"Predicted Body Mass (g)\",\n    color = \"Species\",\n    caption = \"Dashed line represents perfect predictions\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Tidymodels predicted vs actual body mass](08-regression_files/figure-html/fig-tidymodels-linear-1.png){#fig-tidymodels-linear-4 fig-align='center' width=100%}\n:::\n:::\n\n\n::: {.callout-important}\n## Tidymodels Workflow Benefits\n\nThis tidymodels approach provides several advantages:\n\n1. **Clear separation of concerns**: Data splitting, preprocessing, and modeling are distinct steps\n2. **Automatic train/test split**: Built-in support for validation\n3. **Preprocessing pipeline**: Recipe ensures consistent transformations\n4. **Reusable workflows**: Easy to apply the same pipeline to new data\n5. **Standardized metrics**: Consistent evaluation across models\n\nThe test set RMSE and R² provide unbiased estimates of model performance on new data.\n:::\n\n### Cross-Validation with Tidymodels\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Create cross-validation folds\nset.seed(456)\npenguin_folds <- vfold_cv(penguin_train, v = 10, strata = species)\n\ncat(\"Created\", nrow(penguin_folds), \"cross-validation folds\\n\")\n#> Created 10 cross-validation folds\n\n# Fit model using cross-validation\ncv_results <- penguin_wf %>%\n  fit_resamples(\n    resamples = penguin_folds,\n    control = control_resamples(save_pred = TRUE),\n    metrics = metric_set(rmse, rsq, mae)\n  )\n\n# Collect and display metrics\ncv_metrics <- collect_metrics(cv_results)\n\nknitr::kable(cv_metrics,\n             caption = \"10-Fold Cross-Validation Performance\",\n             digits = 3)\n```\n\n::: {#fig-cross-validation-1 .cell-output-display}\n\n\nTable: 10-Fold Cross-Validation Performance\n\n|.metric |.estimator |    mean|  n| std_err|.config         |\n|:-------|:----------|-------:|--:|-------:|:---------------|\n|mae     |standard   | 267.534| 10|  11.696|pre0_mod0_post0 |\n|rmse    |standard   | 334.650| 10|  11.419|pre0_mod0_post0 |\n|rsq     |standard   |   0.832| 10|   0.016|pre0_mod0_post0 |\n\n\n\nCross-validation performance distribution\n:::\n\n```{.r .cell-code}\n\n# Visualize cross-validation results\ncollect_metrics(cv_results, summarize = FALSE) %>%\n  ggplot(aes(x = .metric, y = .estimate)) +\n  geom_boxplot(fill = \"skyblue\", alpha = 0.7) +\n  geom_jitter(width = 0.1, alpha = 0.5, size = 2) +\n  labs(\n    title = \"Cross-Validation Performance Distribution\",\n    subtitle = \"10-fold CV shows model stability across folds\",\n    x = \"Metric\",\n    y = \"Value\"\n  ) +\n  theme_minimal()\n\n# Extract predictions from all folds\ncv_predictions <- collect_predictions(cv_results)\n\n# Plot predictions from cross-validation\nggplot(cv_predictions, aes(x = body_mass_g, y = .pred)) +\n  geom_point(alpha = 0.5, color = \"steelblue\") +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Cross-Validation Predictions\",\n    subtitle = \"All predictions from 10-fold CV\",\n    x = \"Actual Body Mass (g)\",\n    y = \"Predicted Body Mass (g)\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Cross-validation performance distribution](08-regression_files/figure-html/fig-cross-validation-1.png){#fig-cross-validation-2 fig-align='center' width=100%}\n:::\n\n::: {.cell-output-display}\n![Cross-validation predictions](08-regression_files/figure-html/fig-cross-validation-2.png){#fig-cross-validation-3 fig-align='center' width=100%}\n:::\n:::\n\n\n::: {.callout-tip}\n## PROFESSIONAL TIP: Why Cross-Validation?\n\nCross-validation provides:\n\n1. **More reliable performance estimates**: Averages over multiple train/test splits\n2. **Better use of data**: All observations used for both training and validation\n3. **Overfitting detection**: Large difference between training and CV metrics suggests overfitting\n4. **Model comparison**: Fair basis for comparing different modeling approaches\n5. **Hyperparameter tuning**: Essential for selecting optimal model parameters\n:::\n\n### Model Comparison with Tidymodels\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Define multiple model specifications\nlm_spec <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  set_mode(\"regression\")\n\nrf_spec <- rand_forest(trees = 100) %>%\n  set_engine(\"ranger\") %>%\n  set_mode(\"regression\")\n\n# Create workflows for each model\nlm_wf <- workflow() %>%\n  add_recipe(penguin_recipe) %>%\n  add_model(lm_spec)\n\nrf_wf <- workflow() %>%\n  add_recipe(penguin_recipe) %>%\n  add_model(rf_spec)\n\n# Fit both models with cross-validation\nset.seed(789)\nlm_cv <- lm_wf %>%\n  fit_resamples(\n    resamples = penguin_folds,\n    metrics = metric_set(rmse, rsq, mae)\n  )\n\nrf_cv <- rf_wf %>%\n  fit_resamples(\n    resamples = penguin_folds,\n    metrics = metric_set(rmse, rsq, mae)\n  )\n\n# Compare model performance\nmodel_comparison <- bind_rows(\n  collect_metrics(lm_cv) %>% mutate(model = \"Linear Regression\"),\n  collect_metrics(rf_cv) %>% mutate(model = \"Random Forest\")\n)\n\nknitr::kable(model_comparison %>% select(model, .metric, mean, std_err),\n             caption = \"Model Comparison: Linear Regression vs. Random Forest\",\n             digits = 3,\n             col.names = c(\"Model\", \"Metric\", \"Mean\", \"Std Error\"))\n```\n\n::: {#fig-model-comparison-1 .cell-output-display}\n\n\nTable: Model Comparison: Linear Regression vs. Random Forest\n\n|Model             |Metric |    Mean| Std Error|\n|:-----------------|:------|-------:|---------:|\n|Linear Regression |mae    | 267.534|    11.696|\n|Linear Regression |rmse   | 334.650|    11.419|\n|Linear Regression |rsq    |   0.832|     0.016|\n|Random Forest     |mae    | 275.905|    13.512|\n|Random Forest     |rmse   | 351.537|    11.963|\n|Random Forest     |rsq    |   0.811|     0.020|\n\n\n\nModel performance comparison\n:::\n\n```{.r .cell-code}\n\n# Visualize model comparison\nmodel_comparison %>%\n  ggplot(aes(x = model, y = mean, fill = model)) +\n  geom_col() +\n  geom_errorbar(aes(ymin = mean - std_err, ymax = mean + std_err),\n                width = 0.2) +\n  facet_wrap(~ .metric, scales = \"free_y\") +\n  scale_fill_viridis_d(begin = 0.3, end = 0.8) +\n  labs(\n    title = \"Model Performance Comparison\",\n    subtitle = \"Cross-validation results with standard errors\",\n    x = \"Model Type\",\n    y = \"Performance (mean ± SE)\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![Model performance comparison](08-regression_files/figure-html/fig-model-comparison-1.png){#fig-model-comparison-2 fig-align='center' width=100%}\n:::\n:::\n\n\n### Hyperparameter Tuning\n\nOptimizing model parameters is crucial for machine learning models like Random Forest.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Define a model specification with tunable parameters\nrf_tune_spec <- rand_forest(\n  trees = 1000,\n  mtry = tune(),\n  min_n = tune()\n) %>%\n  set_engine(\"ranger\") %>%\n  set_mode(\"regression\")\n\n# Create a workflow with the tunable model\nrf_tune_wf <- workflow() %>%\n  add_recipe(penguin_recipe) %>%\n  add_model(rf_tune_spec)\n\n# Define the grid of parameter values to try\nrf_grid <- grid_regular(\n  mtry(range = c(1, 5)),\n  min_n(range = c(2, 10)),\n  levels = 5\n)\n\n# Tune the model using cross-validation\n# Note: This may take a moment to run\nset.seed(345)\nrf_tune_res <- tune_grid(\n  rf_tune_wf,\n  resamples = penguin_folds,\n  grid = rf_grid,\n  metrics = metric_set(rmse, rsq)\n)\n\n# Collect tuning metrics\nrf_tune_res %>%\n  collect_metrics() %>%\n  filter(.metric == \"rmse\") %>%\n  pivot_longer(cols = c(mtry, min_n), names_to = \"parameter\", values_to = \"value\") %>%\n  ggplot(aes(x = value, y = mean, color = parameter)) +\n  geom_point() +\n  geom_line() +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(title = \"Hyperparameter Tuning Results\", y = \"RMSE (lower is better)\") +\n  theme_minimal()\n\n# Select the best parameters\nbest_rf <- select_best(rf_tune_res, metric = \"rmse\")\nprint(best_rf)\n#> # A tibble: 1 × 3\n#>    mtry min_n .config         \n#>   <int> <int> <chr>           \n#> 1     2    10 pre0_mod10_post0\n\n# Finalize the workflow with the best parameters\nfinal_rf_wf <- finalize_workflow(rf_tune_wf, best_rf)\n\n# Fit the final model to the full training set and evaluate on test set\nfinal_fit <- last_fit(final_rf_wf, penguin_split)\n\n# Show final performance\ncollect_metrics(final_fit)\n#> # A tibble: 2 × 4\n#>   .metric .estimator .estimate .config        \n#>   <chr>   <chr>          <dbl> <chr>          \n#> 1 rmse    standard     291.    pre0_mod0_post0\n#> 2 rsq     standard       0.872 pre0_mod0_post0\n```\n\n::: {.cell-output-display}\n![Hyperparameter tuning results](08-regression_files/figure-html/fig-hyperparameter-tuning-1.png){#fig-hyperparameter-tuning fig-align='center' width=100%}\n:::\n:::\n\n\n::: {.callout-tip}\n## Tuning Strategy\nGrid search explores a defined set of parameters. For more complex models, consider `tune_bayes()` for Bayesian optimization which can be more efficient.\n:::\n\n## Chapter Summary\n\n### Key Concepts\n\n-   **Linear Regression**: Models continuous outcomes as a linear combination of predictors\n-   **Logistic Regression**: Models binary outcomes using the log-odds transformation\n-   **Tidymodels**: A unified framework for modeling in R (parsnip, recipes, rsample, tune, yardstick)\n-   **Cross-Validation**: Resampling method to estimate model performance on unseen data\n-   **Hyperparameter Tuning**: Optimizing model configuration to improve predictive power\n-   **Model Diagnostics**: Checking assumptions (normality, homoscedasticity, linearity) is essential\n\n### R Functions Learned\n\n-   `lm()` / `glm()` - Base R regression functions\n-   `linear_reg()` / `logistic_reg()` / `rand_forest()` - Parsnip model specifications\n-   `recipe()` - Define preprocessing steps\n-   `vfold_cv()` - Create cross-validation folds\n-   `fit_resamples()` - Evaluate models with resampling\n-   `tune_grid()` - Optimize hyperparameters\n-   `collect_metrics()` - Extract performance statistics\n\n### Next Steps\n\nIn the next chapter, we will explore [Advanced Modeling Techniques](09-advanced-modeling.qmd), including how to interpret complex \"black box\" models and how to analyze data collected over time (time series).\n\n### Logistic Regression with Tidymodels\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Prepare binary classification data\npenguins_binary <- penguins %>%\n  mutate(is_adelie = factor(ifelse(species == \"Adelie\", \"Adelie\", \"Other\"),\n                           levels = c(\"Other\", \"Adelie\")))\n\n# Split data\nset.seed(2023)\nbinary_split <- initial_split(penguins_binary, prop = 0.75, strata = is_adelie)\nbinary_train <- training(binary_split)\nbinary_test <- testing(binary_split)\n\n# Create recipe\nlogistic_recipe <- recipe(is_adelie ~ bill_length_mm + bill_depth_mm + flipper_length_mm,\n                         data = binary_train) %>%\n  step_normalize(all_numeric_predictors())\n\n# Specify logistic regression model\nlogistic_spec <- logistic_reg() %>%\n  set_engine(\"glm\") %>%\n  set_mode(\"classification\")\n\n# Create workflow\nlogistic_wf <- workflow() %>%\n  add_recipe(logistic_recipe) %>%\n  add_model(logistic_spec)\n\n# Fit the model\nlogistic_fit <- logistic_wf %>%\n  fit(data = binary_train)\n\n# Get predictions with probabilities\nlogistic_pred <- logistic_fit %>%\n  predict(binary_test, type = \"prob\") %>%\n  bind_cols(logistic_fit %>% predict(binary_test)) %>%\n  bind_cols(binary_test)\n\n# Calculate multiple classification metrics\nlogistic_metrics <- logistic_pred %>%\n  metrics(truth = is_adelie, estimate = .pred_class, .pred_Adelie)\n\nknitr::kable(logistic_metrics,\n             caption = \"Logistic Regression Classification Metrics\",\n             digits = 3)\n```\n\n::: {#fig-tidymodels-logistic-1 .cell-output-display}\n\n\nTable: Logistic Regression Classification Metrics\n\n|.metric     |.estimator | .estimate|\n|:-----------|:----------|---------:|\n|accuracy    |binary     |     0.988|\n|kap         |binary     |     0.976|\n|mn_log_loss |binary     |    15.979|\n|roc_auc     |binary     |     0.000|\n\n\n\nConfusion matrix for Adelie classification\n:::\n\n```{.r .cell-code}\n\n# Create confusion matrix\nconf_mat(logistic_pred, truth = is_adelie, estimate = .pred_class) %>%\n  autoplot(type = \"heatmap\") +\n  labs(title = \"Confusion Matrix: Adelie Classification\") +\n  theme_minimal()\n\n# ROC curve\nlogistic_pred %>%\n  roc_curve(truth = is_adelie, .pred_Adelie) %>%\n  autoplot() +\n  labs(title = \"ROC Curve: Tidymodels Logistic Regression\") +\n  theme_minimal()\n\n# Calculate and display AUC\nauc_value <- logistic_pred %>%\n  roc_auc(truth = is_adelie, .pred_Adelie) %>%\n  pull(.estimate)\n\ncat(\"Area Under the Curve (AUC):\", round(auc_value, 3), \"\\n\")\n#> Area Under the Curve (AUC): 0\n\n# Visualize predicted probabilities\nggplot(logistic_pred, aes(x = bill_length_mm, y = bill_depth_mm,\n                         color = .pred_Adelie, shape = is_adelie)) +\n  geom_point(size = 3, alpha = 0.7) +\n  scale_color_gradient2(low = \"navy\", mid = \"white\", high = \"red\",\n                       midpoint = 0.5) +\n  labs(\n    title = \"Predicted Probabilities: Adelie Classification\",\n    subtitle = paste0(\"AUC = \", round(auc_value, 3)),\n    x = \"Bill Length (mm)\",\n    y = \"Bill Depth (mm)\",\n    color = \"P(Adelie)\",\n    shape = \"Actual Species\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Confusion matrix for Adelie classification](08-regression_files/figure-html/fig-tidymodels-logistic-1.png){#fig-tidymodels-logistic-2 fig-align='center' width=100%}\n:::\n\n::: {.cell-output-display}\n![ROC curve for tidymodels logistic regression](08-regression_files/figure-html/fig-tidymodels-logistic-2.png){#fig-tidymodels-logistic-3 fig-align='center' width=100%}\n:::\n\n::: {.cell-output-display}\n![Confusion matrix for Adelie classification](08-regression_files/figure-html/fig-tidymodels-logistic-3.png){#fig-tidymodels-logistic-4 fig-align='center' width=100%}\n:::\n:::\n\n\n::: {.callout-note}\n## Tidymodels for Classification\n\nThe tidymodels classification workflow provides:\n\n1. **Unified metrics**: Automatic calculation of accuracy, ROC AUC, and other metrics\n2. **Probability predictions**: Easy access to class probabilities\n3. **Visualization tools**: Built-in plotting for confusion matrices and ROC curves\n4. **Consistent interface**: Same workflow structure as regression\n:::\n\n## Comparing Base R and Tidymodels Approaches\n\n### When to Use Each Approach\n\n**Base R (`lm()`, `glm()`) is ideal for:**\n- Quick exploratory analyses\n- Simple models with few predictors\n- Teaching statistical concepts\n- When you need specific model diagnostics\n- Working with traditional statistical output\n\n**Tidymodels is ideal for:**\n- Production modeling pipelines\n- Comparing multiple models\n- Complex preprocessing requirements\n- Cross-validation and resampling\n- Hyperparameter tuning\n- Consistent evaluation across models\n- Reproducible research workflows\n\n### Feature Comparison\n\n| Feature | Base R | Tidymodels |\n|---------|--------|------------\n| **Learning Curve** | Moderate | Steeper initially |\n| **Consistency** | Varies by package | Unified interface |\n| **Preprocessing** | Manual | Automated with recipes |\n| **Cross-validation** | Manual setup | Built-in support |\n| **Model Comparison** | Manual | Streamlined |\n| **Hyperparameter Tuning** | Package-specific | Unified with tune |\n| **Production Deployment** | More complex | Workflow objects |\n| **Extensibility** | High | Very high |\n\n::: {.callout-tip}\n## PROFESSIONAL TIP: Best of Both Worlds\n\nMany practitioners use both approaches:\n\n1.  **Exploration**: Use base R for quick model fitting and diagnostics\n2.  **Refinement**: Transition to tidymodels for rigorous evaluation\n3.  **Production**: Deploy tidymodels workflows for consistency\n4.  **Communication**: Use base R output for traditional audiences, tidymodels for modern reports\n:::\n\n## Exercises\n\n### Base R Exercises\n\n1. Fit a linear regression model predicting body mass from bill length and bill depth. Create a 3D visualization of this relationship using the `plotly` package.\n\n2. Conduct multiple regression with interaction terms between predictors. How does adding interactions improve model performance?\n\n3. Perform model selection using AIC to find the most parsimonious multiple regression model for the penguin data.\n\n4. Create a multinomial logistic regression model to classify all three penguin species based on morphological traits.\n\n5. Compare the performance of logistic regression with other classification methods (e.g., random forest, support vector machines) for species identification.\n\n### Tidymodels Exercises\n\n6. Create a tidymodels workflow for predicting flipper length from body mass and bill measurements. Use 5-fold cross-validation to evaluate performance.\n\n7. Build a recipe that includes polynomial features (e.g., squared terms) for bill length and bill depth. Compare this model's performance to a linear model using cross-validation.\n\n8. Use tidymodels to compare at least three different regression models (e.g., linear regression, random forest, support vector machine) for predicting body mass. Which performs best?\n\n9. Create a classification workflow using tidymodels to predict all three penguin species. Calculate and compare precision, recall, and F1 scores for each species.\n\n10. Implement a hyperparameter tuning workflow using `tune_grid()` to optimize the number of trees and minimum node size for a random forest model predicting body mass.\n\n### Advanced Exercises\n\n11. Split the penguin data by island, use one island as a test set, and evaluate how well models trained on other islands generalize. What does this tell you about geographical variation?\n\n12. Create a nested cross-validation workflow: use an outer loop for model evaluation and an inner loop for hyperparameter tuning. Compare this to simple cross-validation.\n\n13. Develop a complete modeling pipeline that includes:\n    - Data exploration and visualization\n    - Train/test split with stratification\n    - Recipe with appropriate preprocessing\n    - Multiple model specifications\n    - Cross-validation comparison\n    - Final model evaluation on test set\n    - Interpretation of results\n\n14. Use tidymodels to implement a regularized regression (ridge or lasso) and compare it to ordinary least squares. How does regularization affect the coefficients?\n\n15. Create an ensemble model that combines predictions from linear regression, random forest, and gradient boosting models. Does the ensemble outperform individual models?",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}