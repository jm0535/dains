# Hypothesis Testing

## Introduction

Hypothesis testing is a fundamental statistical approach used to make inferences about populations based on sample data. In ecological and forestry research, hypothesis testing helps researchers determine whether observed patterns or differences are statistically significant or merely due to random chance.

## The Logic of Hypothesis Testing

### Null and Alternative Hypotheses

The foundation of hypothesis testing involves two competing hypotheses:

1. **Null Hypothesis (H₀)**: This is the default position that assumes no effect, no difference, or no relationship exists. For example, "There is no difference in tree height between two forest types."

2. **Alternative Hypothesis (H₁ or Hₐ)**: This is the hypothesis that the researcher typically wants to provide evidence for. For example, "There is a significant difference in tree height between two forest types."

### Example in Ecological Research

Let's consider a specific example from forestry research:

- **Research Question**: Is there a difference in the average height of oak trees between Site A and Site B?
- **Null Hypothesis (H₀)**: There is no difference in the average height of oak trees between Site A and Site B.
- **Alternative Hypothesis (H₁)**: There is a significant difference in the average height of oak trees between Site A and Site B.

## Understanding P-values and Significance Levels

### The P-value

The p-value is the probability of obtaining results at least as extreme as those observed, assuming the null hypothesis is true. A smaller p-value indicates stronger evidence against the null hypothesis.

### Significance Level (Alpha)

The significance level, often denoted as α (alpha), represents the threshold for statistical significance. In most research, it is set at 0.05 (5%). This value signifies the maximum acceptable probability of making a Type I error — wrongly rejecting the null hypothesis when it is true.

## Example: Two-Sample t-test

```{r}
# Simulate tree height data for two sites
set.seed(123)
site_A <- rnorm(30, mean = 25, sd = 5)  # 30 trees with mean height 25m
site_B <- rnorm(30, mean = 28, sd = 5)  # 30 trees with mean height 28m

# Create a data frame
tree_data <- data.frame(
  height = c(site_A, site_B),
  site = factor(rep(c("A", "B"), each = 30))
)

# Visualize the data
library(ggplot2)
ggplot(tree_data, aes(x = site, y = height, fill = site)) +
  geom_boxplot() +
  labs(title = "Tree Heights by Site",
       x = "Site",
       y = "Height (m)") +
  theme_minimal()

# Perform a t-test
t_test_result <- t.test(height ~ site, data = tree_data)
print(t_test_result)

# Interpret the result
alpha <- 0.05
if (t_test_result$p.value < alpha) {
  cat("With a p-value of", round(t_test_result$p.value, 4), 
      "we reject the null hypothesis.\n",
      "There is a statistically significant difference in tree heights between sites.")
} else {
  cat("With a p-value of", round(t_test_result$p.value, 4), 
      "we fail to reject the null hypothesis.\n",
      "There is not enough evidence to conclude a significant difference in tree heights.")
}
```

## Example: Using Marine Dataset for Two-Sample t-test

Let's apply the t-test to analyze real data. We'll use our marine dataset to compare fishing yields between different regions:

```{r}
# Load necessary packages
library(tidyverse)

# Load the marine dataset
marine_data <- read_csv("../data/marine/ocean_data.csv")

# View the structure of the dataset
str(marine_data)

# Let's compare fishing yields between two lakes
if("lake" %in% colnames(marine_data) & "values" %in% colnames(marine_data)) {
  # Select two lakes for comparison
  lake_comparison <- marine_data %>%
    filter(lake %in% c("Michigan", "Superior")) %>%
    select(lake, values)
  
  # Perform t-test
  t_test_result <- t.test(values ~ lake, data = lake_comparison)
  
  # Display the results
  print(t_test_result)
  
  # Visualize the comparison
  ggplot(lake_comparison, aes(x = lake, y = values)) +
    geom_boxplot(fill = "lightblue") +
    labs(title = "Comparison of Fishing Yields Between Lakes",
         x = "Lake", y = "Yield Values") +
    theme_minimal()
} else {
  # If the columns don't match exactly, adapt to the actual structure
  # This is a fallback to ensure the code runs with the actual data
  print("Column names don't match expected structure. Adapting...")
  
  # Identify numeric columns for analysis
  numeric_cols <- sapply(marine_data, is.numeric)
  if(sum(numeric_cols) > 0) {
    numeric_col <- names(marine_data)[numeric_cols][1]
    
    # Identify a categorical column for grouping
    cat_cols <- sapply(marine_data, function(x) is.character(x) || is.factor(x))
    if(sum(cat_cols) > 0) {
      cat_col <- names(marine_data)[cat_cols][1]
      
      # Get the two most frequent categories
      top_categories <- names(sort(table(marine_data[[cat_col]]), decreasing = TRUE)[1:2])
      
      # Filter data for these categories
      comparison_data <- marine_data %>%
        filter(!!sym(cat_col) %in% top_categories) %>%
        select(!!sym(cat_col), !!sym(numeric_col))
      
      # Rename columns for easier formula creation
      names(comparison_data) <- c("category", "value")
      
      # Perform t-test
      t_test_result <- t.test(value ~ category, data = comparison_data)
      
      # Display the results
      print(t_test_result)
      
      # Visualize the comparison
      ggplot(comparison_data, aes(x = category, y = value)) +
        geom_boxplot(fill = "lightblue") +
        labs(title = paste("Comparison of", numeric_col, "Between Groups"),
             x = cat_col, y = numeric_col) +
        theme_minimal()
    }
  }
}
```

## Types of Errors in Hypothesis Testing

### Type I and Type II Errors

In hypothesis testing, two types of errors can occur:

1. **Type I Error**: Rejecting a true null hypothesis (false positive).
   - Probability = α (significance level)
   - Example: Concluding there's a difference in tree heights when there actually isn't.

2. **Type II Error**: Failing to reject a false null hypothesis (false negative).
   - Probability = β
   - Example: Failing to detect a real difference in tree heights.

### Statistical Power

Statistical power is the probability of correctly rejecting a false null hypothesis (1 - β). Factors affecting power include:

1. Sample size
2. Effect size
3. Significance level (α)
4. Variability in the data

```{r}
# Demonstrate power calculation for a t-test
library(pwr)

# Calculate power for our example
effect_size <- (28 - 25) / 5  # (mean difference) / standard deviation
power_result <- pwr.t.test(
  n = 30,                    # Sample size per group
  d = effect_size,           # Cohen's d effect size
  sig.level = 0.05,          # Significance level
  type = "two.sample",       # Two-sample t-test
  alternative = "two.sided"  # Two-sided alternative
)

print(power_result)

# Calculate required sample size for 80% power
sample_size_result <- pwr.t.test(
  d = effect_size,           # Cohen's d effect size
  sig.level = 0.05,          # Significance level
  power = 0.8,               # Desired power
  type = "two.sample",       # Two-sample t-test
  alternative = "two.sided"  # Two-sided alternative
)

print(sample_size_result)
```

## One-Sample Tests

One-sample tests compare a sample mean to a known or hypothesized population value.

### One-Sample t-Test

The one-sample t-test is used when:
- The sample is approximately normally distributed
- The population standard deviation is unknown

```{r}
# Simulate tree diameter data
set.seed(456)
tree_diameters <- rnorm(25, mean = 32, sd = 5)  # 25 trees with mean diameter 32cm

# Known reference value (e.g., from previous studies)
reference_diameter <- 30  # cm

# Visualize the data
ggplot(data.frame(diameter = tree_diameters), aes(x = diameter)) +
  geom_histogram(bins = 10, fill = "skyblue", color = "white") +
  geom_vline(xintercept = reference_diameter, color = "red", linetype = "dashed", size = 1) +
  labs(title = "Tree Diameters with Reference Value",
       x = "Diameter (cm)",
       y = "Frequency") +
  annotate("text", x = reference_diameter + 2, y = 5, 
           label = "Reference", color = "red") +
  theme_minimal()

# Perform a one-sample t-test
one_sample_result <- t.test(tree_diameters, mu = reference_diameter)
print(one_sample_result)
```

## Two-Sample Tests

Two-sample tests compare means between two independent groups.

### Independent Samples t-Test

The independent samples t-test is used when:
- Both samples are approximately normally distributed
- The two samples are independent

```{r}
# We already performed this test in our initial example
# Let's visualize it differently

# Create density plots
ggplot(tree_data, aes(x = height, fill = site)) +
  geom_density(alpha = 0.5) +
  labs(title = "Distribution of Tree Heights by Site",
       x = "Height (m)",
       y = "Density") +
  theme_minimal()

# Add mean lines
ggplot(tree_data, aes(x = height, fill = site)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = mean(site_A), color = "red", linetype = "dashed") +
  geom_vline(xintercept = mean(site_B), color = "blue", linetype = "dashed") +
  labs(title = "Distribution of Tree Heights by Site",
       x = "Height (m)",
       y = "Density") +
  theme_minimal()
```

### Paired Samples t-Test

The paired samples t-test is used when:
- Measurements are taken from the same subjects under different conditions
- The differences between pairs are approximately normally distributed

```{r}
# Simulate paired data (e.g., tree growth before and after treatment)
set.seed(789)
before_treatment <- rnorm(20, mean = 15, sd = 3)
after_treatment <- before_treatment + rnorm(20, mean = 2.5, sd = 1)  # Growth effect

# Create a data frame
growth_data <- data.frame(
  tree_id = 1:20,
  before = before_treatment,
  after = after_treatment,
  difference = after_treatment - before_treatment
)

# Visualize paired data
growth_long <- reshape2::melt(growth_data[, c("tree_id", "before", "after")], 
                             id.vars = "tree_id", 
                             variable.name = "time", 
                             value.name = "height")

ggplot(growth_long, aes(x = time, y = height, group = tree_id)) +
  geom_line(alpha = 0.3) +
  geom_point(aes(color = time), size = 3) +
  labs(title = "Tree Heights Before and After Treatment",
       x = "Time",
       y = "Height (m)") +
  theme_minimal()

# Perform a paired t-test
paired_result <- t.test(growth_data$after, growth_data$before, paired = TRUE)
print(paired_result)
```

## Non-Parametric Tests

Non-parametric tests are used when the assumptions of parametric tests (like normality) are violated.

### Mann-Whitney U Test (Wilcoxon Rank-Sum Test)

This is a non-parametric alternative to the independent samples t-test.

```{r}
# Simulate non-normal data (e.g., species counts in two habitats)
set.seed(101)
habitat_A <- rpois(25, lambda = 8)  # Poisson distribution for count data
habitat_B <- rpois(25, lambda = 12)

# Create a data frame
species_data <- data.frame(
  count = c(habitat_A, habitat_B),
  habitat = factor(rep(c("A", "B"), each = 25))
)

# Visualize the data
ggplot(species_data, aes(x = habitat, y = count, fill = habitat)) +
  geom_boxplot() +
  labs(title = "Species Counts by Habitat",
       x = "Habitat",
       y = "Count") +
  theme_minimal()

# Check for normality
shapiro.test(habitat_A)
shapiro.test(habitat_B)

# Perform Mann-Whitney U test
wilcox_result <- wilcox.test(count ~ habitat, data = species_data)
print(wilcox_result)
```

### Wilcoxon Signed-Rank Test

This is a non-parametric alternative to the paired samples t-test.

```{r}
# Simulate non-normal paired data
set.seed(202)
before_restoration <- rpois(20, lambda = 5)
after_restoration <- before_restoration + rpois(20, lambda = 3)

# Create a data frame
restoration_data <- data.frame(
  site_id = 1:20,
  before = before_restoration,
  after = after_restoration,
  difference = after_restoration - before_restoration
)

# Visualize paired data
restoration_long <- reshape2::melt(restoration_data[, c("site_id", "before", "after")], 
                                  id.vars = "site_id", 
                                  variable.name = "time", 
                                  value.name = "species_count")

ggplot(restoration_long, aes(x = time, y = species_count, group = site_id)) +
  geom_line(alpha = 0.3) +
  geom_point(aes(color = time), size = 3) +
  labs(title = "Species Counts Before and After Restoration",
       x = "Time",
       y = "Species Count") +
  theme_minimal()

# Perform Wilcoxon signed-rank test
wilcox_paired_result <- wilcox.test(restoration_data$after, restoration_data$before, paired = TRUE)
print(wilcox_paired_result)
```

## Confidence Intervals

Confidence intervals provide a range of plausible values for a population parameter.

```{r}
# Calculate 95% confidence interval for mean tree height in Site A
ci_result <- t.test(site_A)
print(ci_result$conf.int)

# Visualize confidence interval
mean_height <- mean(site_A)
ci_lower <- ci_result$conf.int[1]
ci_upper <- ci_result$conf.int[2]

ggplot(data.frame(height = site_A), aes(x = height)) +
  geom_histogram(bins = 10, fill = "skyblue", color = "white") +
  geom_vline(xintercept = mean_height, color = "red", size = 1) +
  geom_vline(xintercept = ci_lower, color = "blue", linetype = "dashed") +
  geom_vline(xintercept = ci_upper, color = "blue", linetype = "dashed") +
  annotate("rect", xmin = ci_lower, xmax = ci_upper, ymin = 0, ymax = Inf, 
           fill = "blue", alpha = 0.1) +
  labs(title = "Tree Heights in Site A with 95% Confidence Interval",
       x = "Height (m)",
       y = "Frequency") +
  annotate("text", x = mean_height, y = 8, label = "Mean", color = "red") +
  annotate("text", x = ci_lower - 1, y = 6, label = "Lower CI", color = "blue") +
  annotate("text", x = ci_upper + 1, y = 6, label = "Upper CI", color = "blue") +
  theme_minimal()
```

## Exercises

1. Formulate a hypothesis about a relationship between two variables in the forest inventory dataset.
2. Conduct an appropriate statistical test to evaluate your hypothesis.
3. Calculate the effect size for your test.
4. Interpret the results, including the p-value and effect size.
5. Create a visualization that effectively communicates your findings.

## Summary

In this chapter, we've covered the fundamental concepts and techniques of hypothesis testing in ecological and forestry research:

- Formulating null and alternative hypotheses
- Understanding p-values and significance levels
- Recognizing Type I and Type II errors
- Calculating and interpreting statistical power
- Conducting one-sample, two-sample, and paired tests
- Using non-parametric alternatives when necessary
- Calculating and interpreting confidence intervals

These statistical tools allow researchers to make informed inferences about populations based on sample data, helping to advance knowledge in ecology and forestry.

## Statistical Power

Statistical power is the probability of correctly rejecting the null hypothesis when it is false. It is influenced by:

1. Sample size
2. Effect size
3. Significance level (α)
4. Variability in the data

```{r}
# Demonstrate power calculation for a t-test
library(pwr)

# Calculate power for our example
effect_size <- (28 - 25) / 5  # (mean difference) / standard deviation
power_result <- pwr.t.test(
  n = 30,                    # Sample size per group
  d = effect_size,           # Cohen's d effect size
  sig.level = 0.05,          # Significance level
  type = "two.sample",       # Two-sample t-test
  alternative = "two.sided"  # Two-sided alternative
)

print(power_result)

# Calculate required sample size for 80% power
sample_size_result <- pwr.t.test(
  d = effect_size,           # Cohen's d effect size
  sig.level = 0.05,          # Significance level
  power = 0.8,               # Desired power
  type = "two.sample",       # Two-sample t-test
  alternative = "two.sided"  # Two-sided alternative
)

print(sample_size_result)
